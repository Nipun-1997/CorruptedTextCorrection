{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModellingFasttextAttention.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlk0FYX2tCEagI9G4CXddN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zJHvzmkVmTFs"},"source":["#!pip install tensorflow-gpu==2.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fH9aUk-wlgip","executionInfo":{"status":"ok","timestamp":1616561574334,"user_tz":-330,"elapsed":8647,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"4d1f35a2-de68-4816-cdd4-236c804e9c5b"},"source":["from google.colab import files\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense,Input,GRU,Embedding,Flatten\n","from tensorflow.keras.models import Model\n","import keras.backend as K\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"id":"ZnwcaYaSllX8","executionInfo":{"status":"ok","timestamp":1616561593812,"user_tz":-330,"elapsed":15919,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"c8b890cb-ff40-4821-8f7b-33cba06f8db3"},"source":["uploaded=files.upload()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-04acf371-b19d-4c20-a3ae-1aabf8ea664d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-04acf371-b19d-4c20-a3ae-1aabf8ea664d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving prepared_data.csv to prepared_data.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"vV3IjPWElnV5","executionInfo":{"status":"ok","timestamp":1616561595834,"user_tz":-330,"elapsed":1174,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"b00038a1-d402-437a-9c5e-6ec0247d5266"},"source":["data=pd.read_csv('prepared_data.csv')\n","data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMS_TEXT</th>\n","      <th>ENGLISH_TEXT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>U wan me to \"chop\" seat 4 u nt?</td>\n","      <td>Do you want me to reserve seat for you or not?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yup. U reaching. We order some durian pastry a...</td>\n","      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>They become more ex oredi... Mine is like 25.....</td>\n","      <td>They become more expensive already. Mine is li...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I'm thai. what do u do?</td>\n","      <td>I'm Thai. What do you do?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi! How did your week go? Haven heard from you...</td>\n","      <td>Hi! How did your week go? Haven't heard from y...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            SMS_TEXT                                       ENGLISH_TEXT\n","0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n","1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n","2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n","3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n","4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgC_PFRwmFxR","executionInfo":{"status":"ok","timestamp":1616561599442,"user_tz":-330,"elapsed":678,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"cbaf52aa-ec2b-4745-99d2-31cf76765d6e"},"source":["data['SMS_LEN'] = data['SMS_TEXT'].str.split().apply(len)\n","data = data[data['SMS_LEN'] < 39]\n","\n","\n","\n","data['english_len'] = data['ENGLISH_TEXT'].str.split().apply(len)\n","data = data[data['english_len'] < 40]\n","\n","data['ENGLISH_INPUT'] = '<start> ' + data['ENGLISH_TEXT'].astype(str)\n","data['ENGLISH_OUTPUT'] = data['ENGLISH_TEXT'].astype(str) + ' <end>'\n","\n","data = data.drop(['ENGLISH_TEXT','SMS_LEN','english_len'], axis=1)\n","# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n","\n","print(data.shape)\n","data.iloc[0]['ENGLISH_INPUT']=str(data.iloc[0]['ENGLISH_INPUT'])+' <end>'\n","data.iloc[0]['ENGLISH_OUTPUT']=str(data.iloc[0]['ENGLISH_OUTPUT'])+' <end>'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(1988, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_lGjVgDAmKOm","executionInfo":{"status":"ok","timestamp":1616561604991,"user_tz":-330,"elapsed":2026,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"db8a6e1b-0a34-4a21-f3ab-9688582f093a"},"source":["from sklearn.model_selection import train_test_split\n","train_data,test_data= train_test_split(data,test_size=0.01, random_state=42)\n","print(train_data.shape)\n","print(test_data.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(1968, 3)\n","(20, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_hq9W8cmLuJ","executionInfo":{"status":"ok","timestamp":1616561606801,"user_tz":-330,"elapsed":1160,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"fc93d684-6d3e-4669-f7b7-bae09d0d72e2"},"source":["tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',char_level=False,lower=True,oov_token=True)\n","print(\"SMS_TEXT\")\n","tokenizer.fit_on_texts(train_data['SMS_TEXT'].values)\n","print(\"English text\")\n","tokenizer_e = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',char_level=False,lower=True,oov_token=True)\n","tokenizer_e.fit_on_texts(train_data['ENGLISH_INPUT'].values)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["SMS_TEXT\n","English text\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ErJvZ5x-mWU5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616561650181,"user_tz":-330,"elapsed":1157,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"c19efa95-3294-487f-f45e-6f924d3f82fa"},"source":["encoder_vocabluary=tokenizer.word_index\n","decoder_vocabluary=tokenizer_e.word_index\n","print(len(encoder_vocabluary))\n","print(len(decoder_vocabluary))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["3701\n","3039\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lo3sbHmOlLZ5","executionInfo":{"status":"ok","timestamp":1616561657436,"user_tz":-330,"elapsed":1750,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"91310fe2-ab53-4ebb-a9e5-206583171ff9"},"source":["print(encoder_vocabluary)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["{True: 1, 'u': 2, 'i': 3, 'to': 4, 'me': 5, 'ü': 6, 'at': 7, 'go': 8, 'my': 9, 'so': 10, 'a': 11, 'can': 12, 'you': 13, 'the': 14, 'not': 15, 'haha': 16, 'e': 17, 'hey': 18, 'got': 19, 'in': 20, 'for': 21, 'is': 22, 'ur': 23, 'lor': 24, \"i'm\": 25, 'on': 26, 'ok': 27, 'now': 28, 'time': 29, 'but': 30, 'no': 31, 'then': 32, 'it': 33, '2': 34, 'wat': 35, 'n': 36, 'we': 37, 'of': 38, 'or': 39, 'how': 40, 'r': 41, '4': 42, 'if': 43, 'ah': 44, 'la': 45, 'hi': 46, 'dun': 47, 'one': 48, 'den': 49, 'will': 50, 'meet': 51, 'do': 52, 'wan': 53, 'have': 54, 'all': 55, 'liao': 56, 'out': 57, 'be': 58, 'and': 59, 'up': 60, 'tmr': 61, 'going': 62, 'still': 63, 'are': 64, 'leh': 65, 'call': 66, 'where': 67, 'k': 68, 'ask': 69, 'ya': 70, \"i'll\": 71, 'too': 72, 'oh': 73, 'there': 74, 'get': 75, 'come': 76, 'when': 77, 'like': 78, 'goin': 79, 'home': 80, 'im': 81, 'later': 82, 'today': 83, 'b': 84, 'take': 85, 'your': 86, 'she': 87, 'back': 88, 'think': 89, 'oredi': 90, 'juz': 91, 'just': 92, 'wanna': 93, 'with': 94, 'they': 95, 'free': 96, 'good': 97, 'buy': 98, 'lah': 99, 'late': 100, 'cos': 101, 'w': 102, 'see': 103, 'day': 104, 'that': 105, 'this': 106, 'oso': 107, 'eh': 108, 'dunno': 109, 'c': 110, 'abt': 111, 'only': 112, 'huh': 113, 'her': 114, 'really': 115, 'say': 116, 'need': 117, 'intro': 118, 'was': 119, 'hee': 120, 'dinner': 121, 'more': 122, 'y': 123, 'know': 124, 'already': 125, 'okay': 126, 'thk': 127, 'from': 128, 'hope': 129, 'care': 130, 'chat': 131, 'what': 132, 'rite': 133, 'first': 134, 'msg': 135, 'okie': 136, 'noe': 137, 'yup': 138, 'he': 139, 'lei': 140, 'tt': 141, 'cant': 142, 'ard': 143, 'yet': 144, 'sorry': 145, 'its': 146, 'help': 147, \"it's\": 148, 'after': 149, 'da': 150, 'did': 151, 'hmmm': 152, 'here': 153, 'want': 154, 'pls': 155, 'reach': 156, 'sch': 157, 'make': 158, 'some': 159, 'quite': 160, 'bring': 161, 'doing': 162, 'any': 163, 'also': 164, 'hehe': 165, '1': 166, 'eat': 167, 'nice': 168, 'fren': 169, 'find': 170, 'well': 171, 'sure': 172, 'reply': 173, 'v': 174, 'gd': 175, 'next': 176, 'am': 177, 'by': 178, 'anyway': 179, 'wait': 180, 'wif': 181, 'dont': 182, 'early': 183, 'cya': 184, 'right': 185, 'watch': 186, 'look': 187, 'new': 188, 'enjoy': 189, 'tell': 190, 'work': 191, 'jus': 192, 'long': 193, 'very': 194, 'mind': 195, 'ñ': 196, 'tis': 197, 'nt': 198, 'nite': 199, 'sms': 200, 'lunch': 201, 'soon': 202, 'yr': 203, 'again': 204, 'off': 205, 'much': 206, 'way': 207, 'dat': 208, 'frm': 209, 'coming': 210, 'been': 211, 'change': 212, 'place': 213, 'wk': 214, 'as': 215, 'hello': 216, 'us': 217, 'had': 218, 'outside': 219, 'yun': 220, 'haven': 221, 'lesson': 222, 'ma': 223, 'feel': 224, 'thanx': 225, 'le': 226, 'end': 227, 'show': 228, 'cut': 229, 'anything': 230, 'hav': 231, 'happy': 232, 'coz': 233, 'nd': 234, 'sat': 235, 'same': 236, 'nope': 237, 'maybe': 238, '12': 239, 'din': 240, 'wana': 241, 'bus': 242, '3': 243, 'try': 244, 'shop': 245, 'mayb': 246, 'sis': 247, '5': 248, 'book': 249, 'study': 250, 'who': 251, 'lo': 252, 'must': 253, 'ür': 254, 'number': 255, 'haf': 256, 'last': 257, 'stuff': 258, 'send': 259, 'hmm': 260, 'fun': 261, 'orchard': 262, 'lar': 263, 'working': 264, 'muz': 265, 'our': 266, 'yupz': 267, 'down': 268, 'bad': 269, 'tink': 270, 'gal': 271, 'haiz': 272, 'tonight': 273, 'dear': 274, 'mon': 275, 'mrt': 276, 'stay': 277, 'gee': 278, 'hp': 279, 'saw': 280, 'why': 281, 'hse': 282, 'mah': 283, 'sad': 284, 'lk': 285, 'finish': 286, 'frens': 287, 'which': 288, 'driving': 289, 'thanks': 290, 'morning': 291, 'him': 292, 'other': 293, 'camp': 294, 'mi': 295, 'p': 296, 'phone': 297, 'lect': 298, 'didnt': 299, 'having': 300, 'yah': 301, 'around': 302, 'cannot': 303, 'ppl': 304, 'let': 305, 'hair': 306, 'wah': 307, 'love': 308, 'nvm': 309, 'meeting': 310, 'interested': 311, 'give': 312, 'fri': 313, 'play': 314, 'days': 315, 'use': 316, 'may': 317, 'always': 318, 'thing': 319, 'dog': 320, 'pple': 321, 'great': 322, 'wont': 323, 'short': 324, 'an': 325, 'drivin': 326, 'done': 327, 'online': 328, 'went': 329, 'sci': 330, 'few': 331, 'town': 332, 'class': 333, 'alone': 334, 'btw': 335, 'wad': 336, 'big': 337, 'far': 338, 'sweet': 339, 'guys': 340, 'worry': 341, 'confirm': 342, 'pass': 343, 'shld': 344, 'tml': 345, 'email': 346, 'doin': 347, \"i've\": 348, 'week': 349, 'gonna': 350, 'night': 351, 'bit': 352, 'put': 353, 'job': 354, 'pay': 355, 'nus': 356, 'shall': 357, 'movie': 358, 'yes': 359, 'sleep': 360, 'havent': 361, 'é': 362, 'nothing': 363, 'comin': 364, 'hw': 365, '6': 366, 'house': 367, 'mine': 368, 'chinese': 369, 'name': 370, 'left': 371, \"don't\": 372, 'hor': 373, \"wat's\": 374, \"how's\": 375, 'lot': 376, 'something': 377, 'mean': 378, 'b4': 379, 'actually': 380, 'were': 381, 'havin': 382, 'over': 383, '1st': 384, 'pick': 385, 'fine': 386, 'check': 387, 'bought': 388, 'm': 389, 'school': 390, 'joey': 391, 'xin': 392, 'hall': 393, 'tv': 394, 'before': 395, 'hard': 396, 'aiyo': 397, 'money': 398, 'male': 399, 'kaiez': 400, 'meh': 401, 'talk': 402, 'another': 403, 'said': 404, 'someone': 405, 'better': 406, 'start': 407, 'tat': 408, 'both': 409, \"he's\": 410, 'girl': 411, 'birthday': 412, 'came': 413, 'sun': 414, 'guess': 415, 'yeah': 416, 'life': 417, 'nw': 418, 'tired': 419, 'told': 420, 'forget': 421, 'than': 422, 'workin': 423, 'nvr': 424, 'paiseh': 425, 'near': 426, 'else': 427, 't': 428, 'until': 429, 'those': 430, 'wake': 431, '8': 432, 'called': 433, 'uni': 434, 'shopping': 435, 'hm': 436, 'blue': 437, 'slp': 438, 'together': 439, 'old': 440, 'reaching': 441, 'keep': 442, 'bored': 443, 'anot': 444, 'bugis': 445, 'prob': 446, 'afternoon': 447, 'thgt': 448, 'mum': 449, 'leona': 450, 'com': 451, 'hows': 452, 'fone': 453, 'friends': 454, 'trip': 455, 'leave': 456, 'hai': 457, 'test': 458, 'ans': 459, 'course': 460, 'things': 461, 'stop': 462, 'rest': 463, 'lea': 464, 'forgot': 465, 'cake': 466, 'seat': 467, 'join': 468, 'thought': 469, 'wed': 470, 'add': 471, 'along': 472, 'drink': 473, 'break': 474, 'lots': 475, 'thn': 476, 'close': 477, 'evening': 478, 'photo': 479, 'year': 480, 'studying': 481, 'bout': 482, 'found': 483, 'wun': 484, 'thurs': 485, 'shuhui': 486, '30': 487, 'sunday': 488, 'open': 489, 'cuz': 490, 'miss': 491, 'save': 492, 'ar': 493, 'bk': 494, '10': 495, 'neva': 496, 'female': 497, 'watchin': 498, 'die': 499, 'many': 500, '7': 501, 'guy': 502, 'into': 503, 'dance': 504, 'damn': 505, 'wish': 506, 'should': 507, 'about': 508, 'dreams': 509, 'boy': 510, 'never': 511, 'tonite': 512, 'ben': 513, 'wil': 514, 'his': 515, 'wa': 516, 'gotta': 517, 'centre': 518, 'darlin': 519, 'parents': 520, 'notes': 521, 'most': 522, 'room': 523, 'bbq': 524, 'food': 525, 'pink': 526, 'elaine': 527, \"there's\": 528, 'urself': 529, 'understand': 530, 'cute': 531, 'izzit': 532, 'thats': 533, 'luv': 534, 'car': 535, 's': 536, 'jos': 537, 'might': 538, \"can't\": 539, 'd': 540, 'busy': 541, 'them': 542, \"that's\": 543, 'exams': 544, 'ger': 545, 'nxt': 546, 'plus': 547, 'lotsa': 548, 'amk': 549, 'coffee': 550, 'nv': 551, 'ay': 552, 'lt': 553, 'part': 554, 'dad': 555, 'bt': 556, 'mth': 557, 'walk': 558, 'able': 559, 'lecture': 560, 'daddy': 561, 'suntec': 562, 'case': 563, 'èn': 564, 'seats': 565, 'yourself': 566, 'watching': 567, 'wow': 568, 'till': 569, 'anyone': 570, 'o': 571, 'studyin': 572, 'rem': 573, 'fetch': 574, 'decide': 575, 'has': 576, 'rain': 577, 'duno': 578, 'yest': 579, 'proj': 580, 'reached': 581, 'tot': 582, 'mins': 583, 'half': 584, 'hah': 585, 'earlier': 586, 'means': 587, 'please': 588, 'present': 589, 'bed': 590, 'ù': 591, 'little': 592, 'bishan': 593, 'tai': 594, \"who's\": 595, 'millian': 596, 'shit': 597, 'news': 598, 'real': 599, 'li': 600, 'thank': 601, 'card': 602, 'exam': 603, 'paper': 604, \"we'll\": 605, 'inside': 606, 'ic': 607, 'sian': 608, 'price': 609, 'office': 610, 'prefer': 611, 'tut': 612, 'stil': 613, 'eatin': 614, '20': 615, 'veri': 616, 'gettin': 617, 'ive': 618, 'canteen': 619, 'papers': 620, 'colour': 621, 'fr': 622, '15': 623, 'sentosa': 624, 'luck': 625, 'tomorrow': 626, 'txt': 627, 'exercise': 628, 'once': 629, 'catch': 630, 'even': 631, 'discuss': 632, '25': 633, 'bday': 634, 'drinks': 635, 'smth': 636, 'xy': 637, 'opps': 638, 'collect': 639, 'erm': 640, 'bf': 641, 'two': 642, 'heart': 643, 'st': 644, 'aust': 645, 'hand': 646, 'kind': 647, 'eng': 648, 'sick': 649, 'recently': 650, 'lessons': 651, 'qn': 652, 'nitez': 653, 'hiya': 654, 'oic': 655, 'aiya': 656, 'wrong': 657, 'ago': 658, 'tomw': 659, 'roy': 660, 'sit': 661, 'table': 662, 'choose': 663, 'comp': 664, 'without': 665, 'park': 666, 'loh': 667, 'thru': 668, 'airport': 669, 'win': 670, 'wot': 671, 'man': 672, 'kiss': 673, 'cheese': 674, 'aft': 675, 'choice': 676, 'line': 677, 'cum': 678, 'angel': 679, '2pm': 680, 'hehehe': 681, 'disturb': 682, 'jobs': 683, 'tel': 684, 'weiyi': 685, 'bathe': 686, 'min': 687, 'hug': 688, 'behind': 689, 'ex': 690, 'everybody': 691, 'num': 692, 'used': 693, 'urs': 694, 'mobile': 695, 'enuff': 696, 'msn': 697, 'past': 698, 'kate': 699, 'ones': 700, '11': 701, 'mit': 702, 'because': 703, 'baby': 704, 'bash': 705, 'gals': 706, 'celebrate': 707, 'tues': 708, 'thx': 709, 'wks': 710, '1245': 711, 'abit': 712, 'handphone': 713, 'crazy': 714, 'wine': 715, 'sign': 716, 'asap': 717, 'less': 718, 'amore': 719, 'wuz': 720, \"u'll\": 721, 'sleepin': 722, 'diff': 723, 'everything': 724, 'possible': 725, 'bak': 726, 'depends': 727, 'quiet': 728, 'everyone': 729, 'anytime': 730, 'leaving': 731, 'whats': 732, 'head': 733, 'ad': 734, 'central': 735, 'chi': 736, 'enough': 737, 'weekend': 738, 'don': 739, 'would': 740, 'cheaper': 741, 'person': 742, 'babe': 743, 'stupid': 744, 'interesting': 745, 'sell': 746, 'drive': 747, 'remember': 748, 'game': 749, 'de': 750, 'hv': 751, 'sent': 752, 'lazy': 753, 'wanted': 754, 'hot': 755, 'took': 756, 'face': 757, 'changed': 758, 'violyn': 759, 'taxi': 760, 'acct': 761, 'mei': 762, 'funny': 763, 'eating': 764, 'since': 765, 'learn': 766, 'feeling': 767, 'ha': 768, 'true': 769, 'bot': 770, 'singapore': 771, 'pretty': 772, 'club': 773, 'made': 774, 'each': 775, 'sports': 776, 'whole': 777, 'receive': 778, \"she's\": 779, 'raining': 780, 'instead': 781, 'taking': 782, 'asked': 783, 'boring': 784, 'weather': 785, 'while': 786, 'nearer': 787, 'believe': 788, 'taka': 789, 'talking': 790, 'en': 791, 'gen': 792, 'looking': 793, 'cause': 794, 'anywhere': 795, 'hotmail': 796, 'borrow': 797, 'itz': 798, 'cn': 799, '2nd': 800, 'corner': 801, 'hurry': 802, 'does': 803, 'yiyun': 804, 'hour': 805, 'ranger': 806, 'dae': 807, 'lab': 808, 'vry': 809, 'age': 810, 'stats': 811, 'seen': 812, 'sharis': 813, 'nydc': 814, 'heard': 815, 'either': 816, 'slack': 817, 'j': 818, 'managed': 819, 'friday': 820, 'h': 821, 'boez': 822, 'wawa': 823, 'applied': 824, '24': 825, 'almost': 826, 'cool': 827, 'starts': 828, 'linear': 829, 'website': 830, 'could': 831, 'mango': 832, 'beta': 833, 'jz': 834, 'turn': 835, 'important': 836, 'charge': 837, 'lookin': 838, 'stand': 839, 'rin': 840, 'family': 841, 'haiyoh': 842, '10am': 843, 'student': 844, 'finished': 845, 'helo': 846, 'reen': 847, 'any1': 848, 'wans': 849, 'ecp': 850, 'gota': 851, 'chance': 852, 'woke': 853, 'being': 854, 'bringing': 855, 'laptop': 856, 'small': 857, 'normal': 858, 'lovely': 859, 'sounds': 860, 'outing': 861, 'asking': 862, 'aug': 863, 'interview': 864, 'er': 865, 'sleeping': 866, 'photos': 867, 'started': 868, 'sem': 869, 'run': 870, 'term': 871, 'si': 872, 'yrs': 873, '35': 874, 'mambo': 875, 'bucks': 876, 'sailing': 877, 'icq': 878, 'best': 879, 'theory': 880, 'shd': 881, 'station': 882, 'em': 883, 'mich': 884, 'heh': 885, 'chose': 886, 'award': 887, 'soc': 888, 'bangkok': 889, 'tester': 890, 'yep': 891, 'jeff': 892, 'gelek': 893, 'act': 894, 'faster': 895, 'asleep': 896, 'ter': 897, 'chop': 898, 'pic': 899, 'trying': 900, 'myself': 901, 'gt': 902, 'plan': 903, 'nemo': 904, 'wha': 905, 'discount': 906, 'jordan': 907, 'malay': 908, 'june': 909, 'thur': 910, 'izit': 911, 'yar': 912, 'yours': 913, 'breakfast': 914, 'light': 915, 'body': 916, 'moon': 917, 'stars': 918, 'ends': 919, '0166305681': 920, 'soccer': 921, 'missed': 922, '600': 923, 'probably': 924, 'james': 925, 'matter': 926, 'treat': 927, 'cöz': 928, 'self': 929, 'using': 930, 'gym': 931, 'says': 932, 'pubbin': 933, 'clothes': 934, 'sigh': 935, 'people': 936, 'sometime': 937, 'somewhere': 938, 'keke': 939, 'xf': 940, 'jian': 941, 'bro': 942, 'project': 943, 'waitress': 944, 'broken': 945, 'building': 946, 'local': 947, 'staying': 948, 'temp': 949, 'special': 950, 'fast': 951, 'months': 952, 'seems': 953, 'calls': 954, 'service': 955, 'bottles': 956, 'yo': 957, 'heehee': 958, 'row': 959, 'somethin': 960, 'pub': 961, 'during': 962, 'cheap': 963, 'board': 964, 'idea': 965, 'evaluation': 966, 'location': 967, 'nid': 968, 'crepes': 969, 'cream': 970, 'naughty': 971, 'beautiful': 972, 'ever': 973, 'jog': 974, 'chalet': 975, 'own': 976, 'bz': 977, 'tape': 978, 'dye': 979, 'queensway': 980, 'cheers': 981, 'hunny': 982, 'army': 983, 'waste': 984, 'vivian': 985, 'tats': 986, 'kb': 987, 'sth': 988, 'dare': 989, 'making': 990, \"tt's\": 991, 'though': 992, 'apply': 993, 'smu': 994, 'wondering': 995, 'supposed': 996, 'evenin': 997, 'nose': 998, 'xyan': 999, 'sending': 1000, 'kl': 1001, 'algebra': 1002, 'saying': 1003, 'page': 1004, 'kk': 1005, 'mail': 1006, 'girls': 1007, 'yur': 1008, 'print': 1009, 'return': 1010, 'books': 1011, '50': 1012, 'bitch': 1013, 'lets': 1014, 'library': 1015, 'total': 1016, 'fotos': 1017, 'worth': 1018, 'enuf': 1019, 'major': 1020, 'obvious': 1021, 'settle': 1022, 'anybody': 1023, 'wants': 1024, 'chong': 1025, 'interest': 1026, 'type': 1027, 'sars': 1028, 'beach': 1029, 'bread': 1030, 'til': 1031, 'onwards': 1032, 'least': 1033, 'tight': 1034, 'details': 1035, 'unlimited': 1036, 'mths': 1037, '330': 1038, 'arghh': 1039, 'aiyah': 1040, 'every': 1041, 'west': 1042, 'f': 1043, 'presentation': 1044, 'lady': 1045, 'brand': 1046, 'wet': 1047, 'taste': 1048, 'buyin': 1049, 'yoghurt': 1050, 'father': 1051, 'god': 1052, 'tommorow': 1053, 'straight': 1054, 'takin': 1055, 'paul': 1056, 'mod': 1057, 'joe': 1058, 'lost': 1059, 'friend': 1060, 'wisma': 1061, '6pm': 1062, 'clear': 1063, 'wear': 1064, 'happen': 1065, 'booked': 1066, 'cultural': 1067, 'slightly': 1068, 'eve': 1069, '26': 1070, 'lec': 1071, 'whether': 1072, 'tuition': 1073, 'serangoon': 1074, 'bid': 1075, 'month': 1076, 'tdy': 1077, 'except': 1078, 'upload': 1079, 'iceman': 1080, 'double': 1081, 'fion': 1082, 'yesterday': 1083, 'chiong': 1084, 'leavin': 1085, 'company': 1086, 'tpy': 1087, 'anythin': 1088, 'cash': 1089, 'becos': 1090, 'angry': 1091, '22': 1092, 'speed': 1093, 'away': 1094, 'sg': 1095, 'space': 1096, 'frame': 1097, 'thou': 1098, 'quick': 1099, 'ryan': 1100, 'cookies': 1101, 'workg': 1102, 'report': 1103, 'form': 1104, 'ill': 1105, 'jeans': 1106, 'saturday': 1107, 'bag': 1108, 'round': 1109, 'pt': 1110, 'reali': 1111, 'mt': 1112, 'east': 1113, 'monkey': 1114, 'anyhow': 1115, 'somemore': 1116, 'admin': 1117, 'toa': 1118, 'payoh': 1119, 'between': 1120, 'mother': 1121, 'fall': 1122, 'worried': 1123, 'message': 1124, 'field': 1125, 'wt': 1126, 'drop': 1127, 'booth': 1128, 'business': 1129, 'thu': 1130, 'ere': 1131, 'crowded': 1132, 'driver': 1133, 'playin': 1134, 'relax': 1135, 'yay': 1136, 'toilet': 1137, 'unless': 1138, 'cine': 1139, 'spend': 1140, 'science': 1141, 'taken': 1142, 'mom': 1143, 'follow': 1144, 'yijue': 1145, 'confirmed': 1146, 'meetin': 1147, 'bother': 1148, 'hotel': 1149, 'thkz': 1150, '>': 1151, 'anymore': 1152, 'blk': 1153, '18': 1154, 'maxwell': 1155, 'spending': 1156, 'skin': 1157, 'monday': 1158, 'oni': 1159, 'consider': 1160, 'attached': 1161, 'login': 1162, 'pm': 1163, 'revision': 1164, 'speak': 1165, 'yck': 1166, 'xinyi': 1167, 'tok': 1168, 'pete': 1169, 'ron': 1170, '9': 1171, '30pm': 1172, 'repair': 1173, 'contact': 1174, 'weight': 1175, 'rebecca': 1176, 'nitey': 1177, 'checked': 1178, 'replied': 1179, 'bdae': 1180, 'tom': 1181, 'ring': 1182, 'smile': 1183, 'duty': 1184, 'scare': 1185, 'waiting': 1186, 'area': 1187, 'promise': 1188, 'walking': 1189, 'yunny': 1190, 'hear': 1191, 'wld': 1192, 'advance': 1193, \"children's\": 1194, 'shy': 1195, 'side': 1196, 'every1': 1197, 'yea': 1198, 'temple': 1199, 'glass': 1200, 'fish': 1201, 'co': 1202, 'wru': 1203, 'sunny': 1204, 'kept': 1205, 'cal': 1206, 'icic': 1207, 'darren': 1208, 'isit': 1209, 'smethg': 1210, 'candles': 1211, 'grab': 1212, 'sugardaddy': 1213, 'longer': 1214, 'kp': 1215, 'reb': 1216, 'giv': 1217, 'friendster': 1218, 'rm': 1219, 'hugz': 1220, '016': 1221, 'rather': 1222, 'jo': 1223, 'sorrie': 1224, 'period': 1225, 'seow': 1226, 'sittin': 1227, 'lectures': 1228, 'cancelled': 1229, 'wf': 1230, 'drinkin': 1231, 'topics': 1232, 'gender': 1233, 'copy': 1234, 'getting': 1235, 'hitting': 1236, 'insurance': 1237, 'houses': 1238, 'pool': 1239, 'games': 1240, 'dessert': 1241, 'ordered': 1242, 'rice': 1243, '230': 1244, 'seeing': 1245, \"julia's\": 1246, \"where's\": 1247, 'wombat': 1248, 'tiong': 1249, 'bahru': 1250, 'fringe': 1251, 'sob': 1252, 'simon': 1253, 'kids': 1254, 'dream': 1255, 'borin': 1256, 'bloody': 1257, 'enjoyable': 1258, 'exchange': 1259, 'stuck': 1260, 'qns': 1261, 'newspaper': 1262, 'gp': 1263, 'quit': 1264, 'july': 1265, '180': 1266, 'tanks': 1267, 'todae': 1268, 'programming': 1269, 'hours': 1270, '630': 1271, 'rent': 1272, 'borburn': 1273, 'coke': 1274, 'slot': 1275, 'puzzle': 1276, 'complete': 1277, 'eyes': 1278, 'sum': 1279, '2morrow': 1280, 'moment': 1281, 'nesh': 1282, '23f': 1283, 'tutor': 1284, 'hes': 1285, 'sbs': 1286, 'member': 1287, 'mimi40': 1288, 'gave': 1289, 'deckie': 1290, 'dearies': 1291, 'visit': 1292, 'hang': 1293, 'gang': 1294, 'engine': 1295, 'computing': 1296, 'chope': 1297, 'plain': 1298, 'wats': 1299, 'snacks': 1300, 'remind': 1301, 'wen': 1302, 'wkend': 1303, 'problem': 1304, 'whatever': 1305, 'tp': 1306, 'sellin': 1307, 'wkends': 1308, 'pilates': 1309, 'yor': 1310, 'calling': 1311, 'arh': 1312, 'lobang': 1313, 'orhz': 1314, 'heheh': 1315, 'haiyah': 1316, 'jigsaw': 1317, 'suddenly': 1318, 'uniform': 1319, 'hwa': 1320, 'neo': 1321, 'connect': 1322, 'ric': 1323, 'wads': 1324, 'afraid': 1325, 'blood': 1326, 'lien': 1327, 'finance': 1328, 'clementi': 1329, 'iszit': 1330, 'instant': 1331, 'post': 1332, 'easier': 1333, 'nay': 1334, 'stayed': 1335, 'ple': 1336, 'somerset': 1337, 'sen': 1338, 'clip': 1339, 'expo': 1340, 'rainin': 1341, 'heavily': 1342, 'truth': 1343, 'unique': 1344, 'deserve': 1345, 'bathin': 1346, 'properly': 1347, 'jess': 1348, 'accuse': 1349, 'three': 1350, 'batt': 1351, 'slackin': 1352, 'sianz': 1353, 'relatives': 1354, 'situation': 1355, 'geylang': 1356, 'ivle': 1357, 'popular': 1358, 'dancing': 1359, 'box': 1360, 'hahaha': 1361, 'issit': 1362, 'times': 1363, 'tiring': 1364, '28': 1365, 'jul': 1366, 'college': 1367, 'blur': 1368, 'maldives': 1369, 'roast': 1370, 'ate': 1371, 'yum': 1372, 'bluff': 1373, 'tests': 1374, 'anyways': 1375, 'waitin': 1376, 'feed': 1377, 'farm': 1378, 'xian': 1379, \"millian's\": 1380, 'msia': 1381, 'vet': 1382, 'classified': 1383, 'running': 1384, 'fire': 1385, 'braddell': 1386, 'stayin': 1387, 'hostel': 1388, 'hamster': 1389, 'ache': 1390, 'realised': 1391, 'rushing': 1392, 'ticks': 1393, 'testimonial': 1394, 'lousy': 1395, 'bdåy': 1396, 'registered': 1397, '1215': 1398, 'gem': 1399, 'resume': 1400, 'prepare': 1401, 'sorta': 1402, 'jx': 1403, 'excel': 1404, 'date': 1405, 'top': 1406, 'merina': 1407, 'race': 1408, 'll': 1409, 'meant': 1410, 'vacancies': 1411, 'hdb': 1412, 'bath': 1413, 'mo': 1414, 'tryin': 1415, 'ne': 1416, 'pants': 1417, '3pm': 1418, 'gosh': 1419, 'nobody': 1420, 'tb': 1421, 'continue': 1422, 'pleasure': 1423, 'muaks': 1424, 'cy': 1425, 'lanz': 1426, 'result': 1427, 'flying': 1428, 'color': 1429, 'city': 1430, 'link': 1431, 'basic': 1432, 'tickets': 1433, 'shoppin': 1434, 'thks': 1435, 'exactly': 1436, 'lsm': 1437, 'og': 1438, 'replies': 1439, 'complex': 1440, 'hoh': 1441, 'cz': 1442, 'miz': 1443, 'tks': 1444, 'heavy': 1445, 'training': 1446, 'interviews': 1447, 'impt': 1448, 'tutorial': 1449, 'nex': 1450, 'sendin': 1451, 'fail': 1452, '5pm': 1453, 'solution': 1454, 'intend': 1455, 'darling': 1456, 'wednesday': 1457, 'joan': 1458, 'blame': 1459, 'congrats': 1460, 'meetg': 1461, 'mms': 1462, 'miworld': 1463, 'biddin': 1464, 'pts': 1465, 'shufen': 1466, 'corinna': 1467, 'mr': 1468, 'homepage': 1469, 'young': 1470, 'hungry': 1471, 'cc': 1472, 'sup': 1473, 'cgi': 1474, 'hun': 1475, '2nite': 1476, 'mite': 1477, 'il': 1478, 'fell': 1479, 'mahjong': 1480, '32': 1481, 'thot': 1482, 'cpf': 1483, 'mate': 1484, 'wash': 1485, 'okok': 1486, 'freak': 1487, 'somebody': 1488, 'star': 1489, 'stocks': 1490, 'poor': 1491, 'cold': 1492, 'tough': 1493, 'onli': 1494, 'whens': 1495, 'tents': 1496, 'tent': 1497, 'per': 1498, 'lenient': 1499, 'pieces': 1500, 'wei': 1501, 'ahhh': 1502, 'offer': 1503, 'ikea': 1504, 'scared': 1505, 'brought': 1506, 'wallet': 1507, 'brin': 1508, 'died': 1509, 'bar': 1510, 'tue': 1511, 'int': 1512, 'ken': 1513, 'gone': 1514, 'non': 1515, 'jie': 1516, 'ni': 1517, 'english': 1518, 'nicer': 1519, 'state': 1520, 'sabah': 1521, 'changes': 1522, 'supervisor': 1523, 'suggested': 1524, 'sale': 1525, 'sub': 1526, 'jio': 1527, 'laugh': 1528, 'twice': 1529, 'red': 1530, 'höhò': 1531, 'broke': 1532, 'guide': 1533, 'gud': 1534, 'goodness': 1535, 'point': 1536, 'search': 1537, 'pages': 1538, '130': 1539, 'tinking': 1540, 'plc': 1541, 'public': 1542, 'noon': 1543, 'yrself': 1544, 'mc': 1545, 'parkway': 1546, 'everyday': 1547, 'born': 1548, 'photog': 1549, \"u're\": 1550, 'health': 1551, 'tsk': 1552, 'ticket': 1553, 'ba': 1554, 'pair': 1555, 'knw': 1556, 'cm': 1557, 'resting': 1558, 'thinking': 1559, 'quickly': 1560, '245': 1561, 'jun': 1562, 'session': 1563, 'painting': 1564, 'contract': 1565, 'unit': 1566, 'haircut': 1567, 'toni': 1568, 'bian': 1569, 'id': 1570, 'feelin': 1571, 'cooking': 1572, 'mafan': 1573, 'grocery': 1574, 'lolx': 1575, 'nap': 1576, 'super': 1577, 'lol': 1578, 'movies': 1579, 'earn': 1580, \"en's\": 1581, 'glasses': 1582, 'è': 1583, 'dying': 1584, 'realli': 1585, 'pei': 1586, '440': 1587, 'seem': 1588, 'fac': 1589, 'future': 1590, 'green': 1591, \"haven't\": 1592, 'set': 1593, 'disturbing': 1594, 'results': 1595, 'concentrate': 1596, 'suppose': 1597, '295': 1598, 'punggol': 1599, 'oct': 1600, 'shots': 1601, 'decided': 1602, 'package': 1603, 'fon': 1604, 'chicken': 1605, 'cooked': 1606, 'biz': 1607, 'bin': 1608, 'thai': 1609, 'ahead': 1610, 'elvin': 1611, 'update': 1612, 'yeh': 1613, 'yin': 1614, 'carry': 1615, 'rush': 1616, 'heat': 1617, 'comms': 1618, 'promoting': 1619, 'comm': 1620, 'curious': 1621, 'password': 1622, 'tuas': 1623, 'pouring': 1624, 'basketball': 1625, 'sheesh': 1626, 'michelle': 1627, 'bet': 1628, 'esplanade': 1629, '0165460953': 1630, '27': 1631, 'booking': 1632, 'enjoyin': 1633, 'fox': 1634, 'anyting': 1635, 'store': 1636, 'sia': 1637, 'nuther': 1638, 'cfm': 1639, 'relationship': 1640, 'eaten': 1641, 'brownie': 1642, '7pm': 1643, '730': 1644, 'extra': 1645, 'terminal': 1646, 'meal': 1647, \"she'll\": 1648, 'kiat': 1649, 'hr': 1650, 'ugly': 1651, \"doesn't\": 1652, 'gets': 1653, 'crap': 1654, 'alot': 1655, 'fei': 1656, 'recept': 1657, 'ntuc': 1658, \"didn't\": 1659, 'sultan': 1660, 'wakey': 1661, 'jam': 1662, '545': 1663, '24th': 1664, 'won': 1665, '1200': 1666, 'torquay': 1667, 'ceremony': 1668, 'buzy': 1669, 'their': 1670, 'zouk': 1671, 'rag': 1672, 'weird': 1673, 'tony': 1674, 'po': 1675, 'spore': 1676, 'read': 1677, 'buying': 1678, 'belated': 1679, 'durin': 1680, 'submit': 1681, 'doc': 1682, 'lou': 1683, \"couldn't\": 1684, 'further': 1685, 'hws': 1686, 'lend': 1687, 'petey': 1688, 'nic': 1689, 'remembered': 1690, 'golf': 1691, 'tk': 1692, 'hafta': 1693, 'ave': 1694, 'owis': 1695, 'module': 1696, 'emicakes': 1697, 'mistakes': 1698, 'hallo': 1699, '45pm': 1700, 'party': 1701, 'wkplace': 1702, 'alrite': 1703, 'halo': 1704, 'support': 1705, 'men': 1706, 'mangosteen': 1707, 'shirt': 1708, 'heh2': 1709, 'grandma': 1710, 'air': 1711, 'lkg': 1712, 'gorgeous': 1713, '4th': 1714, 'favour': 1715, 'married': 1716, 'med': 1717, \"what's\": 1718, 'restaurant': 1719, 'arent': 1720, 'action': 1721, 'koe': 1722, 'move': 1723, 'kill': 1724, 'modules': 1725, 'frd': 1726, 'lian': 1727, 'mac': 1728, 'jc': 1729, 'lie': 1730, 'jia': 1731, 'gers': 1732, 'fat': 1733, 'usually': 1734, 'forms': 1735, 'bukit': 1736, 'namly': 1737, 'keen': 1738, 'instructor': 1739, 'record': 1740, 'unix': 1741, 'acc': 1742, 'ubi': 1743, 'häppy': 1744, 'däe': 1745, 'admit': 1746, 'kid': 1747, 'derez': 1748, 'childish': 1749, 'ürself': 1750, 'relive': 1751, 'kiddish': 1752, 'dayz': 1753, 'fiona': 1754, 'xie': 1755, '40pm': 1756, 'rule': 1757, 'canot': 1758, 'gv': 1759, 'fur': 1760, 'superstition': 1761, 'joss': 1762, 'stick': 1763, 'featured': 1764, 'buddha': 1765, 'leg': 1766, 'maintenance': 1767, 'technician': 1768, 'riverwalk': 1769, 'dobby': 1770, 'gaught': 1771, 'netball': 1772, 'captain': 1773, 'converse': 1774, 'mly': 1775, 'tak': 1776, 'percaya': 1777, 'affected': 1778, 'much2': 1779, \"'calrie'\": 1780, '93517902': 1781, 'pig': 1782, 'otherwise': 1783, 'pain': 1784, 'apartment': 1785, 'pics': 1786, 'formed': 1787, 'tday': 1788, 'welcome': 1789, 'singtel': 1790, 'divert': 1791, '1344': 1792, 'voicemail': 1793, '6596400001': 1794, '1800': 1795, '4822800': 1796, 'info': 1797, '019870491': 1798, 'romny1980': 1799, 'lsm1301': 1800, 'photocopy': 1801, '4ü': 1802, 'middle': 1803, 'swan': 1804, 'skip': 1805, 'hve': 1806, 'appearing': 1807, 'plane': 1808, 'okies': 1809, 'loving': 1810, '37': 1811, 'degrees': 1812, 'dnt': 1813, 'ignore': 1814, '3785738': 1815, 'frankly': 1816, 'direct': 1817, 'oters': 1818, 'dyin': 1819, 'dwn': 1820, 'gossip': 1821, '38': 1822, 'museum': 1823, '2gether': 1824, 'lecturer': 1825, 'list': 1826, 'funan': 1827, 'timer': 1828, 'hereen': 1829, 'bite': 1830, 'scratch': 1831, 'considerin': 1832, 'signin': 1833, 'common': 1834, \"pple's\": 1835, 'trainee': 1836, 'bungalow': 1837, 'tomoro': 1838, 'tonnes': 1839, 'vodka': 1840, 'jacuzzi': 1841, 'baked': 1842, '615': 1843, 'answers': 1844, 'blind': 1845, 'forward': 1846, '78': 1847, '128mb': 1848, 'transcend': 1849, 'jetflash': 1850, \"yin's\": 1851, \"b'dae\": 1852, 'hulk': 1853, '7jun': 1854, 'ctrl': 1855, 'stn': 1856, '130pm': 1857, '4e': 1858, 'prepared': 1859, 'vampire': 1860, 'idols': 1861, 'gil': 1862, 'death': 1863, 'sandals': 1864, 'hunks': 1865, 'tex': 1866, \"sound's\": 1867, 'gr8': 1868, 'countin': 1869, 'sharp': 1870, 'babyjontet': 1871, 'honors': 1872, 'christ': 1873, 'meaningless': 1874, 'sardines': 1875, 'tit': 1876, 'bits': 1877, 'bottle': 1878, 'fuji': 1879, 'andrew': 1880, \"your's\": 1881, 'cleared': 1882, 'mess': 1883, 'dredz': 1884, 'moses': 1885, 'taxing': 1886, 'teasin': 1887, '200': 1888, 'detail': 1889, 'aprent': 1890, '99853267': 1891, '11am': 1892, \"we're\": 1893, 'centrept': 1894, 'ramen': 1895, 'dvd': 1896, 'player': 1897, 'hundreds': 1898, 'locksmiths': 1899, 'available': 1900, 'malaysian': 1901, 'whoo': 1902, 'matthew': 1903, 'rocks': 1904, 'ireena': 1905, 'ears': 1906, 'del': 1907, 'lucy': 1908, 'tix': 1909, 'fetching': 1910, 'kreen': 1911, 'ladies': 1912, 'gentleman': 1913, 'china': 1914, 'surf': 1915, 'shorts': 1916, '26th': 1917, \"it'll\": 1918, 'watched': 1919, 'twins': 1920, 'effect': 1921, \"'bout\": 1922, 'yeap': 1923, '1030': 1924, 'doggie': 1925, 'water': 1926, 'pop': 1927, 'lib': 1928, 'bastard': 1929, 'kol': 1930, 'bitches': 1931, 'ñvm': 1932, 'wtc': 1933, 'different': 1934, 'numbers': 1935, 'fujitsu': 1936, 'honest': 1937, 'makeup': 1938, 'attend': 1939, 'invited': 1940, 'cny': 1941, 'sets': 1942, 'perhaps': 1943, 'hellogorgeous': 1944, 'lst': 1945, 'nitw': 1946, 'texd': 1947, 'hopeu': 1948, '4ward': 1949, '2mrw': 1950, 'jaz': 1951, 'lixia': 1952, 'hammy': 1953, '21st': 1954, 'batch': 1955, 'passed': 1956, '60': 1957, 'learnin': 1958, 'fundamental': 1959, 'fund': 1960, 'yoga': 1961, 'communication': 1962, 'probs': 1963, 'credeit': 1964, 'elo': 1965, 'harder': 1966, 'hk': 1967, '96537803': 1968, 'bank': 1969, 'asks': 1970, 'colours': 1971, 'regina': 1972, 'corrina': 1973, 'weekends': 1974, 'credit': 1975, 'relaxed': 1976, 'boxer': 1977, 'dada': 1978, 'macadamia': 1979, 'mama': 1980, 'chocolates': 1981, 'almonds': 1982, 'accessories': 1983, 'gona': 1984, 'bridge': 1985, 'database': 1986, 'agnes': 1987, 'whr': 1988, 'village': 1989, 'needles': 1990, 'animals': 1991, 'dividend': 1992, \"shareholder's\": 1993, 'equity': 1994, 'wheres': 1995, 'note': 1996, 'zhun': 1997, 'sunrise': 1998, 'orientation': 1999, '1015': 2000, 'gua': 2001, 'dollar': 2002, \"i'am\": 2003, 'adverts': 2004, 'telemktg': 2005, 'advert': 2006, 'lead': 2007, 'jay': 2008, 'chou': 2009, 'callin': 2010, 'soz': 2011, 'culdnt': 2012, 'wecan': 2013, 'atm': 2014, 'machine': 2015, 'thkin': 2016, 'reason': 2017, 'focus': 2018, 'mainland': 2019, 'bo': 2020, 'arguing': 2021, \"sun's\": 2022, 'hate': 2023, '8332': 2024, '2650': 2025, '6006': 2026, 'audrey': 2027, 'urgent': 2028, 'sound': 2029, 'lazing': 2030, 'low': 2031, 'kinda': 2032, 'single': 2033, 'event': 2034, 'quality': 2035, 'towels': 2036, 'bare': 2037, \"hi'5\": 2038, 'coast': 2039, 'roller': 2040, 'blades': 2041, 'probl': 2042, 'mike': 2043, 'smokin': 2044, 'skill': 2045, 'tph': 2046, 'size': 2047, 'fit': 2048, 'plse': 2049, 'under': 2050, '103': 2051, 'mng': 2052, 'hols': 2053, 'apartmnt': 2054, 'discussing': 2055, 'reg': 2056, 'gown': 2057, 'matric': 2058, 'measurement': 2059, 'lotion': 2060, 'chauffeur': 2061, 'tibs': 2062, 'promote': 2063, 'fro': 2064, 'siam': 2065, 'pad': 2066, 'nail': 2067, 'recruits': 2068, 'intake': 2069, 'shèésh': 2070, 'äbt': 2071, 'cøz': 2072, 'assigned': 2073, 'jams': 2074, 'abalone': 2075, 'pissed': 2076, 'mmm': 2077, \"i'd\": 2078, 'indian': 2079, 'cup': 2080, 'stalkin': 2081, 'quarrellin': 2082, 'wit': 2083, 'anywae': 2084, 'tc': 2085, 'smoke': 2086, 'goodnight': 2087, 'accurate': 2088, 'accepted': 2089, 'arts': 2090, 'miracle': 2091, 'helping': 2092, 'ctct': 2093, 'waitg': 2094, 'clever': 2095, 'chap': 2096, 'million': 2097, 'strawberry': 2098, 'lavendar': 2099, 'winery': 2100, 'mick': 2101, 'mem': 2102, 'dining': 2103, 'ziping': 2104, 'supper': 2105, 'carrying': 2106, 'broom': 2107, \"papers'\": 2108, 'sol': 2109, 'sprean': 2110, 'perak': 2111, 'hoped': 2112, 'cats': 2113, 'dogs': 2114, 'burn': 2115, 'flyin': 2116, 'quarantine': 2117, 'rminds': 2118, 'jomis': 2119, '40': 2120, 'submitted': 2121, 'butt': 2122, 'siao': 2123, \"they'll\": 2124, 'maintain': 2125, 'length': 2126, 'thin': 2127, 'starting': 2128, '2morro': 2129, 'blinfold': 2130, 'writing': 2131, 'comment': 2132, \"you're\": 2133, 'arrive': 2134, 'whoa': 2135, 'fam': 2136, 'discussion': 2137, 'become': 2138, 'horrible': 2139, 'certain': 2140, 'extent': 2141, 'standard': 2142, 'bookworm': 2143, 'fantasy': 2144, '29': 2145, 'updated': 2146, 'sheet': 2147, 'ethnic': 2148, 'nites': 2149, '93864500': 2150, 'telemarketin': 2151, 'hub': 2152, 'briefin': 2153, 'bristol': 2154, 'april': 2155, 'les': 2156, 'rudi': 2157, 'snoring': 2158, 'drunk': 2159, 'sends': 2160, 'ink': 2161, 'arty': 2162, 'collages': 2163, 'base': 2164, 'u2': 2165, 'walkin': 2166, 'ms': 2167, 'embarrassed': 2168, 'realising': 2169, 'noticed': 2170, '97482959': 2171, 'calculus': 2172, 'beneficial': 2173, 'cost': 2174, '80': 2175, 'live': 2176, 'ùrself': 2177, 'toysarus': 2178, 'places': 2179, 'balloons': 2180, 'pin': 2181, 'peninsula': 2182, 'tq': 2183, 'considering': 2184, 'assistant': 2185, 'merchandiser': 2186, 'polo': 2187, 'ralph': 2188, 'group': 2189, 'hee2': 2190, 'needs': 2191, 'tokin': 2192, 'farrer': 2193, 'filmed': 2194, 'felt': 2195, '8th': 2196, 'deciding': 2197, 'expected': 2198, 'promised': 2199, 'cindy': 2200, 'anyday': 2201, 'overall': 2202, 'stud': 2203, 'score': 2204, 'mid': 2205, \"he'd\": 2206, 'hints': 2207, 'slackg': 2208, 'delay': 2209, 'angle': 2210, 'flowers': 2211, 'mohd': 2212, \"sultan's\": 2213, 'taller': 2214, 'wth': 2215, 'probabilty': 2216, 'clips': 2217, 'rules': 2218, 'ended': 2219, 'outin': 2220, 'ten': 2221, '1102': 2222, 'mood': 2223, 'fierce': 2224, '5plus': 2225, 'wud': 2226, 'replacement': 2227, 'metal': 2228, 'preference': 2229, 'agency': 2230, '1hr': 2231, 'product': 2232, 'boarded': 2233, 'watever': 2234, 'heez': 2235, 'laggin': 2236, 'missy': 2237, 'hectic': 2238, 'hen': 2239, 'photostat': 2240, '15pm': 2241, 'yogi': 2242, 'messages': 2243, 'chocolate': 2244, 'esplamade': 2245, 'tm': 2246, 'jontin': 2247, 'bcos': 2248, 'imagination': 2249, 'cars': 2250, \"'slim'\": 2251, 'yifeng': 2252, 'probab': 2253, 'gain': 2254, 'kg': 2255, '90853276': 2256, 'opportunities': 2257, 'lexus': 2258, 'es300': 2259, '30k': 2260, 'exciting': 2261, 'prizes': 2262, 'global': 2263, 'kay': 2264, 'cultures': 2265, 'cun': 2266, 'pen': 2267, 'mornin': 2268, 'soooo': 2269, 'sux': 2270, 'discovered': 2271, \"ng's\": 2272, 'desk': 2273, 'supported': 2274, 'surely': 2275, 'ava': 2276, 'goodtime': 2277, 'oli': 2278, 'rang': 2279, 'melnite': 2280, 'ifink': 2281, 'sorted': 2282, 'explain': 2283, 'everythin': 2284, 'l8rs': 2285, 'babes': 2286, 'nights': 2287, 'knackered': 2288, 'dreading': 2289, 'upto': 2290, 'handsome': 2291, 'oei': 2292, '65': 2293, '97965247': 2294, 'baking': 2295, 'jar': 2296, 'became': 2297, 'choppin': 2298, 'junmèi': 2299, 'david': 2300, 'ytd': 2301, '6598941248': 2302, 'medical': 2303, 'matriculation': 2304, 'th': 2305, 'gower': 2306, 'wales': 2307, \"'morrow\": 2308, 'random': 2309, '2day': 2310, 'mylife': 2311, 'ding': 2312, 'fassyole': 2313, 'blacko': 2314, 'londn': 2315, 'wearing': 2316, 'bermuda': 2317, 'evy1': 2318, 'garden': 2319, 'noodles': 2320, 'honour': 2321, 'keekee': 2322, 'sympathise': 2323, '58': 2324, 'lt25': 2325, 'perfume': 2326, 'sim': 2327, 'trouble': 2328, 'muji': 2329, 'finally': 2330, 'overseas': 2331, 'indon': 2332, 'laguna': 2333, '8man': 2334, '7n8jun': 2335, 'oso2': 2336, 'pits': 2337, 'nanyang': 2338, 'poly': 2339, '4physiotherapy': 2340, '2take': 2341, 'chem': 2342, 'peeling': 2343, 'burns': 2344, 'jazz': 2345, 'teacher': 2346, 'dancer': 2347, 'tcs': 2348, 'yan': 2349, 'zi': 2350, 'fill': 2351, 'domain': 2352, 've': 2353, 'positive': 2354, '300': 2355, 'yi': 2356, 'stripes': 2357, 'skirt': 2358, 'fucks': 2359, 'sake': 2360, 'freshman': 2361, 'orientatn': 2362, 'dere': 2363, 'internet': 2364, 'front': 2365, 'river': 2366, 'valley': 2367, 'plzzz': 2368, 'sape': 2369, 'nama': 2370, 'boleh': 2371, 'kite': 2372, 'calld': 2373, 'thrus': 2374, 'typo': 2375, 'lift': 2376, 'tailor': 2377, 'comes': 2378, \"they've\": 2379, 'partner': 2380, 'eurasion': 2381, 'juicer': 2382, 'juice': 2383, 'zha': 2384, 'scary': 2385, 'sardine': 2386, 'hold': 2387, 'charger': 2388, 'opera': 2389, 'quitin': 2390, 'hime': 2391, 'burfdae': 2392, 'tht': 2393, 'mad': 2394, 'keeps': 2395, 'barking': 2396, 'buses': 2397, 'sydney': 2398, 'happened': 2399, 'shan': 2400, 'pia': 2401, 'rusty': 2402, 'commenting': 2403, 'popularity': 2404, 'looks': 2405, 'spot': 2406, 'wanting': 2407, 'allday': 2408, 'piss': 2409, 'damning': 2410, 'recruit': 2411, 'acj': 2412, \"cant't\": 2413, 'flowery': 2414, 'understan': 2415, 'boil': 2416, 'hving': 2417, 'picnic': 2418, 'playing': 2419, 'kahi': 2420, 'response': 2421, 'posted': 2422, 'safti': 2423, 'medic': 2424, 'sarawak': 2425, 'ourselves': 2426, 'lik': 2427, 'guai': 2428, 'fw': 2429, 'silent': 2430, 'quaratined': 2431, 'holdin': 2432, 'bookins': 2433, \"a's\": 2434, 'punish': 2435, 'entering': 2436, 'erp': 2437, 'jogging': 2438, 'claim': 2439, 'vat': 2440, 'admirer': 2441, '6points': 2442, 'eye': 2443, 'expect': 2444, 'collectin': 2445, \"jy's\": 2446, 'ps': 2447, 'computer': 2448, 'hetic': 2449, 'sean': 2450, 'select': 2451, '450': 2452, '470': 2453, 'strength': 2454, 'leading': 2455, 'horse': 2456, 'reduce': 2457, 'bfast': 2458, 'aiyoh': 2459, 'mimi': 2460, '0168596707': 2461, 'foot': 2462, 'stays': 2463, 'invisible': 2464, 'ntu': 2465, 'fow': 2466, 'circulatd': 2467, 'gives': 2468, 'niny': 2469, 'mingfang': 2470, 'cross': 2471, 'tokking': 2472, 'met': 2473, 'jocelyn': 2474, 'spoke': 2475, 'fantasia': 2476, 'absolutely': 2477, 'awesome': 2478, 'judges': 2479, 'chosen': 2480, 'balanced': 2481, 'turf': 2482, '800': 2483, 'ey': 2484, 'das': 2485, 'peril': 2486, 'financial': 2487, 'crisis': 2488, 'spk': 2489, 'l8r': 2490, 'lately': 2491, 'ass': 2492, 'smiles': 2493, 'issìt': 2494, 'kpo': 2495, 'abused': 2496, '4mths': 2497, 'ming': 2498, 'lun': 2499, 'strange': 2500, '94': 2501, 'pray': 2502, 'protect': 2503, 'wind': 2504, 'blow': 2505, 'stress': 2506, 'twinkle': 2507, 'system': 2508, 'within': 2509, 'lt26': 2510, 'directly': 2511, 'wrk': 2512, 'lungs': 2513, 'facial': 2514, 'elfie': 2515, '97615390': 2516, 'surface': 2517, \"fion's\": 2518, 'suggestions': 2519, 'london': 2520, 'smashed': 2521, 'dent': 2522, 'missing': 2523, 'channel5': 2524, 'rock': 2525, 'lesser': 2526, 'phones': 2527, 'chit': 2528, '63383526': 2529, \"wk's\": 2530, 'regret': 2531, 'inform': 2532, 'nhs': 2533, 'mistake': 2534, 'hospital': 2535, '2b': 2536, 'terminated': 2537, 'inconvenience': 2538, '830': 2539, 'sailin': 2540, 'bright': 2541, 'guarding': 2542, 'prosperous': 2543, 'wealth': 2544, 'weiyun': 2545, 'loner': 2546, 'pitched': 2547, 'correct': 2548, '96821456': 2549, 'tazz': 2550, 'pouch': 2551, 'gotten': 2552, 'accidents': 2553, 'furthermore': 2554, 'missin': 2555, 'disi': 2556, 'classes': 2557, 'chip': 2558, 'highlight': 2559, 'yui': 2560, 'economics': 2561, 'aspect': 2562, 'fusion': 2563, 'heee': 2564, 'boss': 2565, 'fave': 2566, 'crabs': 2567, 'thkg': 2568, 'yoz': 2569, 'thick': 2570, 'qiao': 2571, 'wrkin': 2572, 'jennifer': 2573, 'hudson': 2574, 'phenomenon': 2575, 'wacky': 2576, 'shinny': 2577, 'costume': 2578, 'specially': 2579, 'b7l': 2580, 'jammer': 2581, 'l': 2582, 'india': 2583, 'hvn': 2584, 'iras': 2585, 'shanghai': 2586, 'holiday': 2587, '415': 2588, 'joy': 2589, 'kiasu': 2590, 'drenched': 2591, \"what're\": 2592, '25bucks': 2593, 'chatting': 2594, '11pm': 2595, 'loyong': 2596, 'vila': 2597, 'charged': 2598, '4000': 2599, '32k': 2600, 'myanmar': 2601, 'workers': 2602, 'commitee': 2603, 'wan2': 2604, 'launching': 2605, 'styles': 2606, 'models': 2607, 'cheng': 2608, 'ting': 2609, 'mummy': 2610, 'suay': 2611, 'farting': 2612, 'engineerin': 2613, 'maths': 2614, 'phy': 2615, 'revise': 2616, 'subject': 2617, 'tonsolitus': 2618, 'aswell': 2619, 'layin': 2620, 'christmas': 2621, '16pp': 2622, \"spinelli's\": 2623, 'heeren': 2624, 'shift': 2625, 'manager': 2626, 'there4': 2627, 'sounded': 2628, \"how'd\": 2629, 'pillow': 2630, 'contrary': 2631, 'views': 2632, \"u'd\": 2633, 'instruction': 2634, 'feels': 2635, 'comfy': 2636, 'rounds': 2637, 'legs': 2638, 'ilol': 2639, 'personally': 2640, 'wuldnt': 2641, 'seldom': 2642, 'bks': 2643, 'mus': 2644, 'convince': 2645, 'mention': 2646, 'reaction': 2647, 'wood': 2648, 'renew': 2649, 'pdl': 2650, 'mrtk': 2651, '445pm': 2652, 'land': 2653, 'alr': 2654, 'eleven': 2655, 'nos': 2656, 'etc': 2657, 'preoccupied': 2658, 'cheer': 2659, 'replying': 2660, 'bedok': 2661, 'stayback': 2662, 'accountin': 2663, 'turning': 2664, 'diz': 2665, 'erase': 2666, 'nanxing': 2667, 'pang': 2668, 'yong': 2669, 'tau': 2670, 'foo': 2671, 'rollin': 2672, 'algebre': 2673, \"tutorial's\": 2674, 'nearest': 2675, 'flirting': 2676, 'chinat': 2677, 'jesslyn': 2678, 'uncle': 2679, '91073084': 2680, 'swim': 2681, 'expensive': 2682, 'thermometer': 2683, 'spoiled': 2684, 'unwell': 2685, 'xp': 2686, 'konichiwa': 2687, 'grls': 2688, 'somebdy': 2689, \"eusoff's\": 2690, 'production': 2691, 'embassy': 2692, 'includes': 2693, '1am': 2694, 'tequila': 2695, 'road': 2696, 'awhile': 2697, 'strong': 2698, 'bishanpark': 2699, 'sez': 2700, 'arab': 2701, 'evry1': 2702, 'buys': 2703, 'hky': 2704, 'peace': 2705, 'weeks': 2706, 'lct': 2707, 'lancome': 2708, 'lcm': 2709, 'foaming': 2710, 'cleansing': 2711, 'gel': 2712, 'combination': 2713, 'dry': 2714, 'pasta': 2715, 'cme': 2716, 'neber': 2717, 'worse': 2718, 'bmi': 2719, 'potatoes': 2720, 'veggies': 2721, 'timing': 2722, 'instruct': 2723, '96792371': 2724, 'usin': 2725, \"we've\": 2726, 'spent': 2727, '2geva': 2728, 'mint': 2729, 'suxs': 2730, 'manners': 2731, \"valentine's\": 2732, 'blessed': 2733, 'happiness': 2734, 'laughter': 2735, 'marshmallow': 2736, 'cz1102': 2737, 'offline': 2738, 'clubrm': 2739, '240': 2740, 'saved': 2741, 'activity': 2742, 'wher': 2743, 'owl': 2744, 'ballot': 2745, 'blurr': 2746, 'bake': 2747, 'storey': 2748, 'chinatown': 2749, 'mkt': 2750, 'hawkes': 2751, 'smith': 2752, 'bodynits': 2753, 'bra': 2754, 'kns': 2755, '10yrs': 2756, 'renovated': 2757, 'facilities': 2758, 'lan': 2759, 'easy': 2760, 'bcz': 2761, 'branded': 2762, 'among': 2763, 'thumb': 2764, '64mb': 2765, 'sec': 2766, 'nex2': 2767, 'uh': 2768, 'math': 2769, 'surname': 2770, 'poem': 2771, 'wonder': 2772, 'planned': 2773, 'slowly': 2774, 'fated': 2775, 'attach': 2776, 'staff': 2777, 'corp': 2778, \"rec'd\": 2779, 'letter': 2780, 'srs': 2781, 'payment': 2782, 'kote': 2783, 'maxy': 2784, \"pest's\": 2785, \"father's\": 2786, 'askin': 2787, 'venue': 2788, 'define': 2789, 'dial': 2790, 'user': 2791, 'dead': 2792, 'colgate': 2793, 'finding': 2794, 'nah': 2795, 'wrks': 2796, 'lyin': 2797, 'rested': 2798, 'match': 2799, 'grounded': 2800, 'dollars': 2801, 'tasty': 2802, 'configured': 2803, 'sowie': 2804, 'lonely': 2805, 'tubes': 2806, 'newsweek': 2807, '42': 2808, 'sharing': 2809, 'shocked': 2810, 'bleach': 2811, 'suying': 2812, 'wooden': 2813, 'aluminium': 2814, 'march': 2815, 'fran': 2816, 'boyf': 2817, 'interviw': 2818, 'exeter': 2819, 'tina': 2820, 'transport': 2821, 'thursday': 2822, 'invite': 2823, '7th': 2824, '02': 2825, '34': 2826, 'boo': 2827, 'seemed': 2828, 'ure': 2829, '2u': 2830, 'slice': 2831, 'ger16': 2832, 'lying': 2833, 'carfinal1': 2834, 'clp': 2835, 'addidas': 2836, 'shoes': 2837, 'iregardles': 2838, 'wht': 2839, 'lydat': 2840, 'seniors': 2841, 'sakae': 2842, 'goodies': 2843, 'emporium': 2844, 'create': 2845, 'wuld': 2846, 'dis': 2847, 'australia': 2848, 'depend': 2849, 'odd': 2850, 'des': 2851, 'frnd': 2852, '99876452': 2853, 'devin': 2854, 'dt': 2855, 'semd': 2856, '13': 2857, '14': 2858, 'liling': 2859, 'chen': 2860, 'academic': 2861, 'benefits': 2862, 'st1232': 2863, 'havoc': 2864, 'smebody': 2865, 'vain': 2866, 'foto': 2867, 'walked': 2868, 'serious': 2869, 'actualy': 2870, 'hammer': 2871, 'hits': 2872, 'concern': 2873, \"he'll\": 2874, 'beat': 2875, 'membership': 2876, 'rot': 2877, 'pl': 2878, 'pj': 2879, 'whose': 2880, 'responding': 2881, 'sh': 2882, 'objection': 2883, 'backout': 2884, 'tennis': 2885, 'joking': 2886, \"we'r\": 2887, 'attendin': 2888, 'ùr': 2889, 'mpsh': 2890, 'extend': 2891, 'tip': 2892, 'derel': 2893, 'retrieve': 2894, 'gloatin': 2895, 'wing': 2896, 'network': 2897, 'causin': 2898, 'slow': 2899, 'josh': 2900, 'teach': 2901, 'machines': 2902, 'ahhhh': 2903, 'pon': 2904, 'oversea': 2905, 'bird': 2906, 'tournament': 2907, 'lucky': 2908, 'tray': 2909, 'jade': 2910, 'barmed': 2911, 'mohamad': 2912, 'consolidating': 2913, 'responses': 2914, 'responds': 2915, '>poke': 2916, 'poke<': 2917, 'traffic': 2918, 'reading': 2919, 'collec': 2920, 'full': 2921, 'babez': 2922, '45': 2923, '1700': 2924, '1730': 2925, \"time's\": 2926, 'moboy': 2927, 'happenin': 2928, 'kèke': 2929, 'thgs': 2930, 'innocent': 2931, 'pure': 2932, 'øsø': 2933, 'hähaa': 2934, '0845': 2935, 'lt32': 2936, 'formal': 2937, 'arrangemt': 2938, 'realistic': 2939, 'saimee': 2940, 'outsider': 2941, '1400': 2942, 'jame': 2943, 'seed': 2944, 'shucks': 2945, 'envelope': 2946, 'replace': 2947, 'cca': 2948, 'bonds': 2949, 'knows': 2950, 'totally': 2951, 'detest': 2952, 'conscious': 2953, 'factory': 2954, 'outlet': 2955, 'mb': 2956, 'opening': 2957, 'bck': 2958, 'sweety': 2959, 'terok': 2960, 'wöuld': 2961, 'secret': 2962, 'trg': 2963, 'informed': 2964, 'cheong': 2965, 'insights': 2966, 'gained': 2967, 'safe': 2968, 'hahå': 2969, 'publicity': 2970, 'xuhui': 2971, '2am': 2972, 'hide': 2973, 'classmate': 2974, 'kai': 2975, 'qin': 2976, 'trim': 2977, 'topshop': 2978, 'ridge': 2979, 'wide': 2980, 'plans': 2981, 'aljunied': 2982, 'dumpling': 2983, 'contactin': 2984, '225': 2985, '375': 2986, 'url': 2987, 'exhib': 2988, '715': 2989, 'isnt': 2990, 're': 2991, 'noel': 2992, 'review': 2993, 'queen': 2994, 'officially': 2995, '93466348': 2996, 'knit': 2997, 'sweater': 2998, 'ematerials': 2999, 'calender': 3000, 'realized': 3001, \"'\": 3002, 'overprotective': 3003, 'cept': 3004, 'treated': 3005, 'menghong': 3006, 'squash': 3007, 'ours': 3008, 'causeway': 3009, 'lancaster': 3010, 'neway': 3011, \"b'day\": 3012, 'extreme': 3013, 'eca': 3014, 'pubing': 3015, 'dance1': 3016, 'centro': 3017, 'smooth': 3018, 'dna': 3019, 'harlow': 3020, 'stalk': 3021, '1yr': 3022, 'police': 3023, 'irritating': 3024, 'wasnt': 3025, 'phoned': 3026, 'ofc': 3027, 'petty': 3028, 'assessment': 3029, 'black': 3030, 'jack': 3031, 'boredom': 3032, 'arghz': 3033, 'recommendations': 3034, 'explicit': 3035, 'terence': 3036, 'aik': 3037, 'randy': 3038, 'awkward': 3039, 'kingshead': 3040, 'lover': 3041, 'cedes': 3042, 'lame': 3043, 'sayin': 3044, 'harry': 3045, 'potter': 3046, '33': 3047, \"kid's\": 3048, 'selling': 3049, 'stinky': 3050, 'wrking': 3051, 'ellen': 3052, 'rays': 3053, 'leaves': 3054, 'worries': 3055, 'bay': 3056, 'sleepy': 3057, 'slept': 3058, 'hrs': 3059, 'favor': 3060, 'belt': 3061, 'canvas': 3062, 'cloth': 3063, 'fault': 3064, 'starhub': 3065, 'mght': 3066, 'timetable': 3067, 'häf': 3068, 'disease': 3069, 'boggy': 3070, 'biatch': 3071, 'malayu': 3072, 'kayu': 3073, 'tried': 3074, 'meijun': 3075, 'bd': 3076, 'acceptable': 3077, 'contraction': 3078, 'nyp': 3079, 'marketin': 3080, 'jenniffer': 3081, 'tpp': 3082, 'bth': 3083, 'zoo': 3084, 'celebrating': 3085, 'jiang': 3086, 'lin': 3087, 'dian': 3088, 'sloggin': 3089, 'jux': 3090, 'unrestricted': 3091, 'electives': 3092, 'high': 3093, \"'okie'\": 3094, '25ch': 3095, 'esther': 3096, 'roughly': 3097, 'gift': 3098, 'stinge': 3099, 'smting': 3100, 'knock': 3101, '530pm': 3102, 'huiqi': 3103, 'farewell': 3104, 'marina': 3105, 'coca': 3106, 'spare': 3107, 'surprise': 3108, 'choc': 3109, 'yummy': 3110, 'jong': 3111, \"tmr's\": 3112, 'g': 3113, 'giving': 3114, 'goodnite': 3115, 'shame': 3116, 'gail': 3117, 'vill': 3118, 'yogasana': 3119, 'inaug': 3120, 'university': 3121, 'center': 3122, 'anythings': 3123, 'thout': 3124, 'such': 3125, 'daytime': 3126, 'slpin': 3127, 'dumb': 3128, 'funky': 3129, 'sam': 3130, 'checkin': 3131, '630pm': 3132, 'tanjong': 3133, 'pagar': 3134, 'ntg': 3135, 'càrè': 3136, 'ä': 3137, 'tiffany': 3138, 'gek1005': 3139, 'grp': 3140, 'guyz': 3141, 'cherish': 3142, 'webpage': 3143, 'language': 3144, 'clean': 3145, '100': 3146, 'loss': 3147, 'inperialmusic': 3148, 'listening2the': 3149, 'weirdest': 3150, 'track': 3151, 'leafcutter': 3152, 'john': 3153, 'insects': 3154, 'molested': 3155, 'plumbing': 3156, 'remixed': 3157, 'evil': 3158, 'acid': 3159, 'jurong': 3160, 'hoe': 3161, 'flu': 3162, 'stuffs': 3163, 'graphic': 3164, 'design': 3165, 'crown': 3166, '91074867': 3167, 'stepbystep': 3168, 'toking': 3169, \"chinatown's\": 3170, 'hawker': 3171, 'cleanin': 3172, 'inauguration': 3173, '9am': 3174, 'newquay': 3175, 'postcard': 3176, '1im': 3177, 'talkin': 3178, 'telemktin': 3179, 'higher': 3180, 'xroom': 3181, \"joan's\": 3182, 'guinea': 3183, 'pigs': 3184, 'genting': 3185, 'smallville': 3186, 'dozin': 3187, 'none': 3188, 'nowhere': 3189, 'kno': 3190, 'innit': 3191, 'access': 3192, 'vpn': 3193, 'dload': 3194, 'stella': 3195, 'fixed': 3196, 'shoppg': 3197, 'brunswick': 3198, 'alannah': 3199, 'hill': 3200, 'income': 3201, 'buildingnear': 3202, 'chijmes': 3203, 'simple': 3204, 'cook': 3205, 'luckily': 3206, 'enlarge': 3207, 'creative': 3208, 'queue': 3209, 'holidayin': 3210, 'fitness': 3211, 'roadshow': 3212, '6mth': 3213, '2mths': 3214, 'goodiebags': 3215, 'luckyspin': 3216, 'junction': 3217, \"jul'03\": 3218, '63366822': 3219, 'reminder': 3220, 'force': 3221, 'anythg': 3222, 'celine': 3223, '6590957823': 3224, 'nth': 3225, '1day': 3226, 'thts': 3227, '>im': 3228, '<': 3229, '0164330931': 3230, 'fetchin': 3231, 'app': 3232, 'hava': 3233, 'readin': 3234, 'monkees': 3235, 'howdy': 3236, 'sausage': 3237, 'jen': 3238, 'remembe': 3239, 'passin': 3240, 'usual': 3241, 'tours': 3242, 'kisses': 3243, 'cooling': 3244, 'national': 3245, 'weekday': 3246, 'kitten': 3247, 'mel': 3248, 'owes': 3249, 'control': 3250, 'diet': 3251, 'drag': 3252, 'muack': 3253, 'zepol': 3254, 'dum': 3255, 'haih': 3256, 'zzz': 3257, 'starz': 3258, 'tite': 3259, '23': 3260, 'frog': 3261, 'wannna': 3262, 'capital': 3263, 'lifè': 3264, 'kwang': 3265, 'chow': 3266, '5th': 3267, 'vacancy': 3268, 'bruce': 3269, 'almighty': 3270, 'asp': 3271, 'jsp': 3272, 'bc': 3273, 'thailand': 3274, 'mahz': 3275, 'jiejie': 3276, 'vcd': 3277, 'samurai': 3278, 'añoèr': 3279, 'zping': 3280, '7plus': 3281, 'upstairs': 3282, 'waking': 3283, 'cherry': 3284, 'practice': 3285, 'jùz': 3286, 'jon': 3287, 'spain': 3288, 'dinero': 3289, 'bill': 3290, \"'rents\": 3291, '000pes': 3292, '£48': 3293, 'naggin': 3294, 'bil1': 3295, '12pm': 3296, 'ample': 3297, 'wich': 3298, 'level': 3299, \"jac's\": 3300, 'whackers33': 3301, 'darn': 3302, 'dom': 3303, 'japanese': 3304, 'indians': 3305, 'sall': 3306, 'shexy': 3307, 'kick': 3308, 'boxing': 3309, 'fully': 3310, 'model': 3311, 'oops': 3312, 'alsmost': 3313, 'shoe': 3314, 'block': 3315, '221': 3316, 'boon': 3317, 'lay': 3318, 'nokia': 3319, '7250': 3320, 'trade': 3321, '719': 3322, 'configure': 3323, 'piece': 3324, 'postings': 3325, 'plaza': 3326, 'sing': 3327, 'cafe': 3328, 'cartel': 3329, 'topic': 3330, 'covering': 3331, '97856124': 3332, 'holidays': 3333, 'fen': 3334, 'mistress': 3335, \"kua's\": 3336, 'cdd': 3337, 'reported': 3338, 'immediately': 3339, 'becoz': 3340, 'against': 3341, 'compliance': 3342, 'realize': 3343, 'keepin': 3344, 'shiok': 3345, 'arrived': 3346, 'moisturise': 3347, 'rub': 3348, 'circular': 3349, 'motion': 3350, 'tone': 3351, 'jelly': 3352, 'onto': 3353, 'tap': 3354, 'lala': 3355, 'zip': 3356, 'lose': 3357, 'remb': 3358, 'colourful': 3359, 'map': 3360, 'printer': 3361, 'huge': 3362, 'planning': 3363, 'suan': 3364, 'thicker': 3365, 'dropping': 3366, 'adress': 3367, '18liaos': 3368, 'legalised': 3369, '4lotsa': 3370, 'liaos': 3371, 'wadever': 3372, 'thrice': 3373, 'maya': 3374, 'bless': 3375, 'raffles': 3376, 'gottem': 3377, 'sunburn': 3378, 'taxin': 3379, 'loan': 3380, 'waz': 3381, 'fm25': 3382, 'dan': 3383, '4gt': 3384, 'suit': 3385, 'err': 3386, 'confident': 3387, 'hopefully': 3388, 'lasts': 3389, 'order': 3390, 'durian': 3391, 'pastry': 3392, 'havng': 3393, 'pesterin': 3394, 'jerk': 3395, 'wishes': 3396, 'levels': 3397, 'sunperks': 3398, 'points': 3399, 'apr': 3400, '1627': 3401, 'promo': 3402, 'yucks': 3403, 'remove': 3404, \"noi'm\": 3405, 'avent': 3406, 'spoken': 3407, 'nit': 3408, 'js': 3409, 'reunion': 3410, 'tireness': 3411, 'draws': 3412, 'across': 3413, 'fade': 3414, 'flexibility': 3415, 'windows': 3416, 'soul': 3417, 'begin': 3418, 'enter': 3419, 'dreamland': 3420, 'oyasuminasai': 3421, 'rv': 3422, 'hol': 3423, 'ages': 3424, 'roads': 3425, 'rvx': 3426, 'ke': 3427, 'sine': 3428, 'melting': 3429, '132': 3430, '135': 3431, \"'yo\": 3432, \"up'\": 3433, 'unsure': 3434, \"friend's\": 3435, \"long's\": 3436, 'everythings': 3437, '11th': 3438, 'oie': 3439, 'slpt': 3440, 'biscuits': 3441, 'january': 3442, \"ben's\": 3443, \"wa's\": 3444, 'nel': 3445, '96473920': 3446, 'satsgettin': 3447, '47per': 3448, 'touch': 3449, 'grave': 3450, 'oriedi': 3451, 'dug': 3452, 'circuit': 3453, 'awards': 3454, 'petition': 3455, 'william': 3456, 'hung': 3457, 'nopez': 3458, 'nthing': 3459, 'aishya': 3460, 'terrible': 3461, 'combat': 3462, 'brown': 3463, 'envelop': 3464, 'eymani': 3465, 'frequent': 3466, 'headache': 3467, 'oreadi': 3468, 'yunñy': 3469, 'wonderful': 3470, 'remain': 3471, 'hugs': 3472, 'jìayin': 3473, 'nx': 3474, 'juli': 3475, 'pao': 3476, 'qi': 3477, 'wo': 3478, 'kilo': 3479, 'officers': 3480, 'findin': 3481, 'channel': 3482, 'memorable': 3483, \"huixin's\": 3484, 'hsewarming': 3485, '517': 3486, 'law': 3487, 'environment': 3488, 'hamsters': 3489, 'teaching': 3490, 'korean': 3491, 'rec': 3492, 'scold': 3493, 'encouraging': 3494, 'como': 3495, 'listened2the': 3496, 'plaid': 3497, 'album': 3498, 'air1': 3499, 'hilarious': 3500, 'braindance': 3501, 'ofstuff': 3502, \"aphex's\": 3503, 'abel': 3504, 'hav2hear': 3505, 'sn': 3506, 'wrg': 3507, 'installing': 3508, 'wireless': 3509, '2sensitive': 3510, '2made': 3511, 'cancellation': 3512, 'forfeited': 3513, 'crumpler': 3514, 'slighty': 3515, 'suspect': 3516, 'seven': 3517, 'thirty': 3518, 'fountain': 3519, 'indonesian': 3520, 'sanur': 3521, 'sep': 3522, 'ready': 3523, 'peach': 3524, 'tasts': 3525, 'lush': 3526, 'digi': 3527, 'muffin': 3528, '8310': 3529, 'nsf': 3530, 'poorest': 3531, 'boys': 3532, 'roaming': 3533, 'trial': 3534, \"m1's\": 3535, 'alert': 3536, 'www': 3537, 'log': 3538, 'screen': 3539, 'expanding': 3540, 'sideways': 3541, 'remedy': 3542, 'definitely': 3543, 'confide': 3544, 'gossiping': 3545, 'fyi': 3546, 'collecting': 3547, 'drawer': 3548, 'camera': 3549, 'beneath': 3550, 'pale': 3551, 'thinkin': 3552, 'nitenite': 3553, 'swimming': 3554, \"meijun's\": 3555, 'share': 3556, 'rude': 3557, 'wu': 3558, 'dao': 3559, 'sneaks': 3560, 'perfectly': 3561, 'disappointed': 3562, 'ndp': 3563, 'parade': 3564, 'foam': 3565, 'avoid': 3566, '5419814': 3567, 'sir': 3568, \"i'\": 3569, 'knack': 3570, 'ing': 3571, 'step': 3572, '4rm': 3573, 'knockin': 3574, \"isn't\": 3575, 'qet': 3576, 'giro': 3577, 'subm': 3578, 'mohmd': 3579, 'cover': 3580, '12bucks': 3581, \"anyone's\": 3582, 'ttfn': 3583, 'jez': 3584, 'whill': 3585, 'forever': 3586, 'scattered': 3587, 'everywhere': 3588, 'dats': 3589, 'watcha': 3590, 'zheng': 3591, 'fix': 3592, 'enjoying': 3593, 'sales': 3594, 'spinelli': 3595, 'oreo': 3596, 'sq': 3597, 'drain': 3598, 'cycling': 3599, 'account': 3600, 'panjang': 3601, 'plz': 3602, 'toaster': 3603, 'drinking': 3604, 'years': 3605, 'boyfriend': 3606, 'jolene': 3607, \"there'll\": 3608, '17': 3609, 'spread': 3610, 'four': 3611, 'dirty': 3612, 'lemme': 3613, 'responsible': 3614, 'academy': 3615, '1na': 3616, 'freshmen': 3617, 'inaugration': 3618, 'timah': 3619, 'clinic': 3620, 'annie': 3621, 'civilisation': 3622, 'vv': 3623, 'grabbing': 3624, 'ice': 3625, 'pau': 3626, 'gif': 3627, 'bone': 3628, 'tooth': 3629, 'plenty': 3630, 'write': 3631, 'profiles': 3632, 'littat': 3633, 'earrings': 3634, 'doesnt': 3635, 'jap': 3636, 'suggest': 3637, 'sizzler': 3638, 's56': 3639, 'glad': 3640, 'guess3': 3641, 'importantly': 3642, 'regrets': 3643, 'gstring': 3644, 'roman': 3645, 'font': 3646, 'spacing': 3647, 'ocean': 3648, 'rd': 3649, 'alreadi': 3650, 'bug': 3651, 'irritate': 3652, 'cry': 3653, 'slacking': 3654, 'diarrhoea': 3655, 'nothin': 3656, 'needed': 3657, 'surpass': 3658, 'stairs': 3659, 'knees': 3660, 'stoppin': 3661, 'homework': 3662, '1pm': 3663, 'flight': 3664, 'snatch': 3665, 'josssticks': 3666, 'carè': 3667, 'sold': 3668, 'passwd': 3669, 'sumting': 3670, 'messy': 3671, 'jiayin': 3672, \"wawa's\": 3673, '153': 3674, 'bstop': 3675, 'click': 3676, 'view': 3677, 'ofcourse': 3678, 'jordon': 3679, 'by1': 3680, 'cityhall': 3681, 'gran': 3682, 'cu': 3683, 'honi': 3684, 'organise': 3685, 'vesak': 3686, 'activities': 3687, 'pocay': 3688, 'wocay': 3689, '4eva': 3690, 'stricter': 3691, 'con': 3692, 'cushy': 3693, 'chair': 3694, \"customer's\": 3695, 'se': 3696, 'ignorin': 3697, 'alright': 3698, 'kaypoh': 3699, 'arnd': 3700, 'aim': 3701}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_wP1MxznJB0","executionInfo":{"status":"ok","timestamp":1616562138772,"user_tz":-330,"elapsed":1466,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"aedf57d5-2edb-4ca4-b98a-dd1a774c0c9e"},"source":["print(decoder_vocabluary)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["{True: 1, '<start>': 2, 'you': 3, 'i': 4, 'to': 5, 'the': 6, 'are': 7, 'is': 8, 'and': 9, 'for': 10, 'at': 11, 'me': 12, 'a': 13, 'so': 14, 'my': 15, 'can': 16, 'then': 17, 'your': 18, 'go': 19, \"i'm\": 20, 'it': 21, 'not': 22, 'have': 23, \"don't\": 24, 'ok': 25, 'want': 26, 'haha': 27, 'what': 28, 'in': 29, 'do': 30, 'hey': 31, 'going': 32, 'be': 33, 'of': 34, 'now': 35, 'on': 36, 'that': 37, 'or': 38, 'will': 39, 'just': 40, 'but': 41, 'how': 42, 'we': 43, 'got': 44, 'know': 45, 'time': 46, 'with': 47, 'see': 48, 'am': 49, 'already': 50, 'no': 51, 'tomorrow': 52, 'if': 53, 'hi': 54, 'think': 55, 'yes': 56, 'meet': 57, \"it's\": 58, 'good': 59, 'all': 60, 'out': 61, 'there': 62, 'still': 63, 'okay': 64, 'because': 65, 'where': 66, 'come': 67, 'call': 68, 'up': 69, 'one': 70, 'also': 71, 'too': 72, 'like': 73, 'when': 74, \"i'll\": 75, 'get': 76, 'this': 77, 'from': 78, 'about': 79, 'oh': 80, 'home': 81, 'today': 82, 'back': 83, 'need': 84, 'very': 85, 'right': 86, 'why': 87, 'later': 88, 'take': 89, 'she': 90, 'did': 91, 'day': 92, 'was': 93, 'ask': 94, 'free': 95, 'late': 96, 'they': 97, 'buy': 98, 'around': 99, 'only': 100, 'first': 101, 'night': 102, 'really': 103, 'her': 104, 'thanks': 105, 'number': 106, 'sorry': 107, 'please': 108, 'by': 109, 'he': 110, 'doing': 111, 'message': 112, 'never': 113, 'school': 114, 'dinner': 115, 'more': 116, 'after': 117, 'hope': 118, 'care': 119, 'next': 120, 'chat': 121, 'yet': 122, 'maybe': 123, \"can't\": 124, '2': 125, 'must': 126, 'way': 127, \"haven't\": 128, 'people': 129, 'help': 130, 'coming': 131, 'mind': 132, 'some': 133, 'here': 134, 'hehe': 135, 'as': 136, 'introduce': 137, 'hello': 138, 'girl': 139, \"didn't\": 140, 'well': 141, 'work': 142, 'working': 143, 'anyway': 144, 'friend': 145, 'bring': 146, 'any': 147, 'make': 148, 'quite': 149, 'should': 150, 'lecture': 151, 'driving': 152, 'been': 153, 'nice': 154, 'having': 155, 'soon': 156, 'house': 157, 'wait': 158, 'something': 159, 'tonight': 160, 'phone': 161, 'find': 162, 'sure': 163, 'look': 164, 'anything': 165, 'say': 166, 'new': 167, 'an': 168, 'long': 169, 'eat': 170, 'again': 171, 'thought': 172, 'enjoy': 173, 'early': 174, 'tell': 175, 'much': 176, 'week': 177, 'reach': 178, 'place': 179, 'friends': 180, 'birthday': 181, '12': 182, 'reply': 183, 'lunch': 184, 'send': 185, 'us': 186, 'watch': 187, 'off': 188, 'had': 189, 'before': 190, 'cannot': 191, 'saturday': 192, \"won't\": 193, 'love': 194, \"that's\": 195, 'who': 196, 'happy': 197, 'outside': 198, '1': 199, 'cut': 200, 'book': 201, 'lesson': 202, 'meeting': 203, 'sigh': 204, 'course': 205, 'give': 206, 'change': 207, 'wow': 208, 'show': 209, 'bus': 210, '3': 211, 'last': 212, 'feel': 213, 'sms': 214, 'same': 215, 'sleep': 216, 'monday': 217, 'our': 218, '30': 219, 'has': 220, 'may': 221, 'chinese': 222, \"what's\": 223, 'sister': 224, 'year': 225, \"i've\": 226, 'friday': 227, 'study': 228, 'yourself': 229, 'huh': 230, '6': 231, 'stuff': 232, 'which': 233, 'down': 234, 'lots': 235, 'dear': 236, 'orchard': 237, 'mrt': 238, 'studying': 239, 'bit': 240, 'went': 241, 'stay': 242, 'try': 243, 'watching': 244, 'hmm': 245, 'days': 246, \"how's\": 247, 'bad': 248, 'fun': 249, 'ah': 250, 'let': 251, 'end': 252, 'science': 253, 'bought': 254, 'morning': 255, 'handphone': 256, 'nothing': 257, 'him': 258, 'other': 259, 'always': 260, 'better': 261, '4': 262, 'hair': 263, 'interested': 264, 'thursday': 265, 'saw': 266, 'dog': 267, 'sad': 268, 'shopping': 269, 'great': 270, 'done': 271, '7': 272, '5': 273, 'wants': 274, 'few': 275, 'alone': 276, 'than': 277, 'sweet': 278, 'camp': 279, 'male': 280, '8': 281, 'shop': 282, 'guys': 283, 'another': 284, 'said': 285, 'pass': 286, 'yeah': 287, 'lot': 288, 'bored': 289, 'yun': 290, 'evening': 291, 'sunday': 292, 'busy': 293, 'online': 294, 'anyone': 295, 'town': 296, 'class': 297, 'shall': 298, 'remember': 299, 'laugh': 300, 'use': 301, 'called': 302, 'talk': 303, 'worry': 304, 'enough': 305, 'mean': 306, 'short': 307, 'hee': 308, 'together': 309, 'actually': 310, 'says': 311, 'life': 312, 'put': 313, 'job': 314, 'nus': 315, 'told': 316, 'female': 317, 'fine': 318, 'afternoon': 319, 'movie': 320, 'until': 321, 'would': 322, 'big': 323, 'them': 324, 'far': 325, 'money': 326, 'asked': 327, 'mine': 328, 'left': 329, 'university': 330, 'both': 331, 'eating': 332, 'old': 333, 'came': 334, '15': 335, 'girls': 336, 'were': 337, 'over': 338, 'tired': 339, 'pick': 340, 'play': 341, 'computer': 342, 'two': 343, 'forget': 344, 'joey': 345, 'xin': 346, 'hall': 347, 'hard': 348, \"there's\": 349, 'everyone': 350, 'name': 351, 'someone': 352, 'confirm': 353, 'wednesday': 354, 'thank': 355, 'finish': 356, 'guess': 357, 'hand': 358, 'probably': 359, '10': 360, 'leave': 361, 'might': 362, 'things': 363, 'tv': 364, 'else': 365, 'stop': 366, 'rest': 367, 'yesterday': 368, 'project': 369, 'forgot': 370, 'thing': 371, 'near': 372, \"you're\": 373, 'those': 374, 'email': 375, 'darling': 376, 'does': 377, 'room': 378, 'blue': 379, 'reaching': 380, 'photo': 381, 'bugis': 382, '45': 383, 'month': 384, 'pay': 385, '25': 386, 'leona': 387, 'miss': 388, 'trip': 389, 'test': 390, 'dance': 391, \"he's\": 392, 'reached': 393, 'yup': 394, 'cake': 395, 'check': 396, 'boy': 397, 'wake': 398, 'looking': 399, 'months': 400, 'keep': 401, 'along': 402, 'parents': 403, 'drink': 404, 'break': 405, 'getting': 406, 'dad': 407, 'food': 408, 'understand': 409, 'found': 410, 'finished': 411, 'possible': 412, 'sleeping': 413, 'shuhui': 414, 'save': 415, 'many': 416, 'into': 417, 'taking': 418, 'damn': 419, 'seat': 420, 'join': 421, 'dreams': 422, 'ben': 423, 'his': 424, 'talking': 425, 'yours': 426, 'daddy': 427, \"we'll\": 428, 'sign': 429, 'ends': 430, 'tutorial': 431, 'notes': 432, 'most': 433, 'pink': 434, 'elaine': 435, 'luck': 436, 'cute': 437, 'plus': 438, 'leaving': 439, 'boyfriend': 440, 'car': 441, 'jos': 442, '2pm': 443, 'till': 444, 'wanted': 445, 'wish': 446, 'park': 447, 'feeling': 448, 'eh': 449, 'bishan': 450, 'pm': 451, 'shit': 452, 'coffee': 453, 'exam': 454, 'office': 455, 'hour': 456, 'start': 457, 'close': 458, 'part': 459, 'hm': 460, 'tuesday': 461, 'weeks': 462, 'boring': 463, 'text': 464, 'crazy': 465, 'once': 466, 'everything': 467, 'able': 468, 'suntec': 469, 'case': 470, 'open': 471, 'photos': 472, 'seats': 473, 'kind': 474, 'started': 475, 'mum': 476, 'lessons': 477, 'raining': 478, 'thinking': 479, 'while': 480, 'die': 481, 'asking': 482, 'guy': 483, 'wrong': 484, 'fetch': 485, 'introduction': 486, 'exams': 487, 'trying': 488, 'without': 489, 'rain': 490, 'kiss': 491, 'through': 492, 'made': 493, 'changed': 494, 'minutes': 495, 'account': 496, 'half': 497, 'confirmed': 498, 'earlier': 499, 'means': 500, 'weight': 501, 'present': 502, 'bed': 503, 'little': 504, 'lea': 505, \"who's\": 506, 'news': 507, 'real': 508, 'woke': 509, 'card': 510, 'centre': 511, 'paper': 512, 'inside': 513, 'price': 514, 'prefer': 515, 'theatre': 516, \"doesn't\": 517, '20': 518, 'baby': 519, 'canteen': 520, 'papers': 521, 'june': 522, 'central': 523, 'sentosa': 524, 'sounds': 525, 'u': 526, 'asks': 527, 'exercise': 528, 'catch': 529, 'walk': 530, 'even': 531, 'tickets': 532, 'whether': 533, 'drinks': 534, 'xy': 535, 'er': 536, 'important': 537, 'weekend': 538, 'heart': 539, 'problem': 540, 'faint': 541, 'australia': 542, 'sun': 543, 'sick': 544, 'recently': 545, 'en': 546, 'nearer': 547, 'cause': 548, 'ago': 549, 'roy': 550, 'waiting': 551, 'sit': 552, 'gee': 553, 'table': 554, 'decide': 555, 'choose': 556, 'bucks': 557, 'point': 558, 'airport': 559, 'nevermind': 560, 'cheese': 561, 'funny': 562, 'choice': 563, 'line': 564, 'instead': 565, 'amk': 566, 'angel': 567, 'singapore': 568, 'pretty': 569, 'oops': 570, 'replied': 571, 'whole': 572, 'disturb': 573, 'jobs': 574, 'using': 575, 'answer': 576, 'weiyi': 577, '40': 578, 'millian': 579, 'behind': 580, 'staying': 581, 'used': 582, 'mobile': 583, 'msn': 584, 'past': 585, 'kate': 586, 'pub': 587, 'during': 588, 'ones': 589, '11': 590, 'seen': 591, 'barbeque': 592, 'heard': 593, 'celebrate': 594, 'station': 595, '30pm': 596, 'honey': 597, 'wine': 598, 'less': 599, 'july': 600, 'almost': 601, 'depends': 602, 'cool': 603, 'sending': 604, 'quiet': 605, 'saying': 606, 'mail': 607, 'anytime': 608, 'head': 609, 'total': 610, 'address': 611, 'nope': 612, 'family': 613, 'discuss': 614, 'question': 615, 'k': 616, 'chance': 617, 'cheaper': 618, 'person': 619, 'stupid': 620, 'interesting': 621, 'drive': 622, 'outing': 623, 'li': 624, 'game': 625, 'interview': 626, 'buying': 627, 'expensive': 628, 'module': 629, 'sent': 630, 'lazy': 631, 'starts': 632, 'hot': 633, 'sailing': 634, 'took': 635, 'face': 636, 'man': 637, 'violyn': 638, 'taxi': 639, 'asleep': 640, 'since': 641, 'learn': 642, 'myself': 643, 'true': 644, 'east': 645, 'mother': 646, 'missed': 647, 'breakfast': 648, 'body': 649, 'club': 650, 'each': 651, 'stars': 652, 'business': 653, \"she's\": 654, 'collect': 655, 'sports': 656, 'weather': 657, 'believe': 658, 'taka': 659, 'kaiez': 660, 'building': 661, 'malay': 662, 'gen': 663, 'hug': 664, 'seems': 665, 'hotmail': 666, 'borrow': 667, 'add': 668, '2nd': 669, 'corner': 670, 'hurry': 671, 'yiyun': 672, 'ranger': 673, 'lab': 674, 'age': 675, 'statistics': 676, 'goes': 677, 'sharis': 678, 'bash': 679, 'nydc': 680, 'answers': 681, 'colour': 682, 'either': 683, 'dye': 684, 'slack': 685, 'boez': 686, 'making': 687, 'amore': 688, 'though': 689, 'wawa': 690, 'applied': 691, 'details': 692, 'linear': 693, 'algebra': 694, 'website': 695, 'could': 696, 'library': 697, 'books': 698, 'checked': 699, 'mango': 700, 'mom': 701, 'keeps': 702, 'different': 703, 'engineering': 704, 'turn': 705, 'stand': 706, 'whatever': 707, 'st': 708, 'selling': 709, 'weekends': 710, 'rin': 711, 'ouch': 712, '10am': 713, 'student': 714, 'reen': 715, 'slept': 716, 'everybody': 717, 'tight': 718, 'bathing': 719, 'babe': 720, 'bringing': 721, 'laptop': 722, 'small': 723, 'normal': 724, 'lovely': 725, 'slacking': 726, 'knows': 727, 'lady': 728, 'contact': 729, 'its': 730, 'english': 731, 'semester': 732, 'run': 733, 'died': 734, 'term': 735, 'booked': 736, 'slightly': 737, '35': 738, '26': 739, 'walking': 740, 'icq': 741, 'best': 742, 'theory': 743, 'hmmm': 744, 'except': 745, 'mich': 746, 'rush': 747, 'award': 748, 'win': 749, 'bangkok': 750, 'tester': 751, \"friend's\": 752, 'jeff': 753, 'com': 754, 'faster': 755, 'supervisor': 756, 'picture': 757, 'somebody': 758, 'per': 759, 'nemo': 760, 'discount': 761, 'toa': 762, 'payoh': 763, 'playing': 764, 'light': 765, 'speak': 766, 'moon': 767, '0166305681': 768, 'soccer': 769, 'receive': 770, 'lose': 771, '600': 772, 'alright': 773, 'james': 774, 'matter': 775, 'treat': 776, 'anymore': 777, 'gym': 778, 'chose': 779, 'years': 780, 'clothes': 781, 'attached': 782, 'ger': 783, 'somewhere': 784, 'xf': 785, '9': 786, \"isn't\": 787, 'brother': 788, 'waitress': 789, 'broken': 790, 'yea': 791, 'temple': 792, 'local': 793, 'lien': 794, 'anywhere': 795, 'special': 796, 'fast': 797, 'calls': 798, 'service': 799, 'bottles': 800, 'row': 801, 'cheap': 802, 'idea': 803, 'dying': 804, 'evaluation': 805, 'drinking': 806, 'location': 807, 'cream': 808, 'naughty': 809, 'beautiful': 810, 'ever': 811, 'ordered': 812, 'seeing': 813, 'chalet': 814, 'own': 815, 'tape': 816, 'queensway': 817, 'cheers': 818, 'army': 819, 'waste': 820, 'vivian': 821, 'looks': 822, 'questions': 823, 'kb': 824, 'apply': 825, 'smu': 826, 'wondering': 827, 'supposed': 828, '24': 829, 'hours': 830, 'eyes': 831, 'nose': 832, 'moment': 833, 'xyan': 834, 'kl': 835, 'page': 836, 'watched': 837, 'e': 838, 'print': 839, 'return': 840, '50': 841, 'bitch': 842, 'computing': 843, 'gorgeous': 844, 'charge': 845, \"let's\": 846, 'worth': 847, 'calling': 848, 'major': 849, 'obvious': 850, 'settle': 851, 'likes': 852, 'whoops': 853, 'eng': 854, 'anybody': 855, 'chong': 856, 'interest': 857, 'type': 858, 'sars': 859, 'beach': 860, 'bread': 861, 'ecp': 862, 'onwards': 863, 'least': 864, \"couldn't\": 865, 'goodnight': 866, 'being': 867, 'unlimited': 868, 'these': 869, 'sell': 870, 'west': 871, 'presentation': 872, 'brand': 873, 'ic': 874, 'times': 875, 'august': 876, 'dollars': 877, 'college': 878, 'blur': 879, 'wet': 880, 'taste': 881, 'ya': 882, 'yoghurt': 883, 'god': 884, 'straight': 885, 'solution': 886, 'paul': 887, 'flying': 888, 'joe': 889, 'lost': 890, 'wisma': 891, 'rushing': 892, 'wear': 893, 'lousy': 894, 'cultural': 895, 'bath': 896, 'embarrassing': 897, 'mambo': 898, 'tuition': 899, 'serangoon': 900, 'bid': 901, 'group': 902, 'wah': 903, 'upload': 904, 'iceman': 905, 'double': 906, 'fion': 907, 'company': 908, 'cash': 909, 'angry': 910, 'esplanade': 911, '22': 912, 'gelek': 913, 'speed': 914, 'space': 915, 'points': 916, 'frame': 917, 'mahjong': 918, 'quick': 919, 'ryan': 920, 'cookies': 921, 'report': 922, 'form': 923, 'jeans': 924, 'bag': 925, 'monkey': 926, 'scared': 927, 'anyhow': 928, 'brought': 929, 'managed': 930, 'jordan': 931, 'between': 932, 'gotten': 933, 'fall': 934, 'worried': 935, 'j': 936, 'field': 937, 'twice': 938, 'four': 939, 'booth': 940, 'crowded': 941, 'driver': 942, \"hasn't\": 943, 'relax': 944, 'toilet': 945, 'soc': 946, 'unless': 947, 'holiday': 948, 'spend': 949, 'telephone': 950, 'taken': 951, 'loud': 952, 'yijue': 953, 'decided': 954, 'bother': 955, 'hotel': 956, '45pm': 957, 'self': 958, 'reserve': 959, 'block': 960, '18': 961, 'spending': 962, 'okie': 963, 'skin': 964, 'plan': 965, 'act': 966, 'eaten': 967, 'password': 968, 'login': 969, 'sometime': 970, 'revision': 971, 'yeap': 972, 'yck': 973, 'xinyi': 974, 'pete': 975, 'ron': 976, 'mo': 977, 'extra': 978, 'repair': 979, 'rebecca': 980, '17': 981, '4th': 982, 't': 983, 'smile': 984, 'duty': 985, 'party': 986, 'inauguration': 987, 'area': 988, 'promise': 989, 'step': 990, 'hear': 991, 'advance': 992, \"children's\": 993, 'shy': 994, 'side': 995, 're': 996, 'live': 997, 'joss': 998, 'minute': 999, 'glass': 1000, 'fish': 1001, 'sunny': 1002, 'kept': 1003, 'darren': 1004, 'pig': 1005, 'otherwise': 1006, 'apartment': 1007, 'candles': 1008, 'sugar': 1009, 'longer': 1010, 'information': 1011, 'reb': 1012, 'middle': 1013, 'skip': 1014, 'boarded': 1015, 'hugs': 1016, '016': 1017, 'rather': 1018, 'jo': 1019, 'period': 1020, 'sitting': 1021, 'lectures': 1022, 'cancelled': 1023, 'topics': 1024, 'gender': 1025, 'copy': 1026, 'ha': 1027, 'hitting': 1028, 'considering': 1029, 'insurance': 1030, 'jog': 1031, 'houses': 1032, 'pool': 1033, 'games': 1034, 'dessert': 1035, 'rice': 1036, 'forward': 1037, \"julia's\": 1038, \"yin's\": 1039, 'wombat': 1040, 'tiong': 1041, 'fringe': 1042, 'simon': 1043, 'kids': 1044, 'dream': 1045, 'enjoyable': 1046, 'exchange': 1047, 'stuck': 1048, 'newspaper': 1049, 'quit': 1050, 'taxing': 1051, \"you'll\": 1052, '180': 1053, 'tanks': 1054, \"we're\": 1055, 'programming': 1056, 'rent': 1057, 'borburn': 1058, 'coke': 1059, 'slot': 1060, 'puzzle': 1061, 'complete': 1062, 'reaches': 1063, 'lt': 1064, 'fetching': 1065, 'nesh': 1066, '23': 1067, 'tutor': 1068, 'sbs': 1069, 'member': 1070, 'mimi40': 1071, 'gave': 1072, 'deckie': 1073, 'collected': 1074, 'erm': 1075, 'visit': 1076, 'dare': 1077, 'bitches': 1078, 'hang': 1079, 'gang': 1080, 'chop': 1081, 'numbers': 1082, 'plain': 1083, 'snacks': 1084, 'remind': 1085, 'passed': 1086, 'fundamental': 1087, 'pilates': 1088, 'problems': 1089, 'credit': 1090, 'jigsaw': 1091, 'suddenly': 1092, 'etc': 1093, 'uniform': 1094, 'hwa': 1095, 'connect': 1096, 'ric': 1097, 'village': 1098, 'afraid': 1099, 'blood': 1100, 'finance': 1101, 'clementi': 1102, 'instant': 1103, 'accurate': 1104, 'post': 1105, 'easier': 1106, 'stayed': 1107, 'orientation': 1108, 'clip': 1109, 'expo': 1110, 'heavily': 1111, 'truth': 1112, 'unique': 1113, 'deserve': 1114, 'properly': 1115, 'jess': 1116, '330': 1117, 'board': 1118, 'accuse': 1119, 'battery': 1120, 'relatives': 1121, 'every': 1122, 'situation': 1123, 'coast': 1124, 'geylang': 1125, 'size': 1126, 'ivle': 1127, 'popular': 1128, 'dancing': 1129, 'box': 1130, 'holidays': 1131, 'matriculation': 1132, 'three': 1133, 'tiring': 1134, '1st': 1135, 'maldives': 1136, 'roast': 1137, 'ate': 1138, 'bluff': 1139, 'stalking': 1140, 'father': 1141, 'tests': 1142, 'feed': 1143, 'million': 1144, 'farm': 1145, \"millian's\": 1146, 'singaporean': 1147, 'malaysia': 1148, 'vet': 1149, 'classified': 1150, 'fire': 1151, 'braddell': 1152, 'hostel': 1153, '6pm': 1154, 'hamster': 1155, 'clear': 1156, 'submitted': 1157, 'realised': 1158, 'intro': 1159, 'testimonial': 1160, 'thinks': 1161, 'arrive': 1162, 'registered': 1163, 'happen': 1164, 'gem': 1165, 'resume': 1166, 'prepare': 1167, 'excel': 1168, 'date': 1169, 'top': 1170, 'merina': 1171, 'race': 1172, 'decision': 1173, \"father's\": 1174, 'meant': 1175, 'telemarketing': 1176, 'vacancies': 1177, 'hdb': 1178, 'april': 1179, 'pants': 1180, 'nobody': 1181, 'continue': 1182, 'pleasure': 1183, 'result': 1184, 'city': 1185, 'link': 1186, 'basic': 1187, 'needs': 1188, 'felt': 1189, '1pm': 1190, 'exactly': 1191, 'happened': 1192, 'lsm': 1193, 'o': 1194, 'og': 1195, 'replies': 1196, 'complex': 1197, 'mood': 1198, 'heavy': 1199, 'training': 1200, 'interviews': 1201, 'tpy': 1202, 'wk': 1203, '5pm': 1204, 'intend': 1205, 'messages': 1206, 'chocolate': 1207, 'joan': 1208, 'blame': 1209, 'congratulations': 1210, 'away': 1211, 'mms': 1212, 'miworld': 1213, 'sg': 1214, 'bidding': 1215, 'center': 1216, 'shufen': 1217, 'corinna': 1218, 'sucks': 1219, 'mr': 1220, 'homepage': 1221, 'young': 1222, 'hungry': 1223, 'cc': 1224, 'cgi': 1225, 'babes': 1226, 'fell': 1227, '32': 1228, 'medical': 1229, 'cpf': 1230, 'mate': 1231, 'wash': 1232, 'london': 1233, 'freak': 1234, 'star': 1235, 'stocks': 1236, 'poor': 1237, 'cold': 1238, 'tough': 1239, 'overseas': 1240, 'indonesian': 1241, 'tents': 1242, 'tent': 1243, 'planning': 1244, 'lenient': 1245, 'pieces': 1246, 'wei': 1247, 'offer': 1248, 'mei': 1249, 'ikea': 1250, 'juice': 1251, 'scary': 1252, 'wallet': 1253, 'bar': 1254, 'ken': 1255, 'gone': 1256, 'non': 1257, 'nicer': 1258, 'state': 1259, 'sabah': 1260, 'changes': 1261, 'collecting': 1262, 'suggested': 1263, 'plaza': 1264, \"sister's\": 1265, 'sale': 1266, 'sub': 1267, 'red': 1268, 'broke': 1269, 'guide': 1270, 'goodness': 1271, 'search': 1272, 'pages': 1273, 'missing': 1274, 'channel': 1275, 'public': 1276, 'mc': 1277, 'parkway': 1278, 'everyday': 1279, 'born': 1280, 'health': 1281, 'yay': 1282, 'giggle': 1283, 'paid': 1284, 'round': 1285, 'pair': 1286, 'resting': 1287, 'quickly': 1288, 'cineleisure': 1289, 'scare': 1290, 'jun': 1291, 'session': 1292, 'painting': 1293, 'contract': 1294, 'unit': 1295, 'haircut': 1296, 'toni': 1297, 'cooking': 1298, 'troublesome': 1299, 'nap': 1300, 'super': 1301, 'movies': 1302, 'earn': 1303, \"you'd\": 1304, 'follow': 1305, 'glasses': 1306, 'accompany': 1307, 'seem': 1308, 'faculty': 1309, 'future': 1310, 'green': 1311, 'set': 1312, 'accounting': 1313, 'disturbing': 1314, 'results': 1315, 'concentrate': 1316, 'chinatown': 1317, 'swimming': 1318, 'suppose': 1319, 'windows': 1320, '295': 1321, 'punggol': 1322, 'october': 1323, 'shots': 1324, 'maxwell': 1325, 'package': 1326, 'fon': 1327, 'bbq': 1328, 'chicken': 1329, 'cooked': 1330, \"valentine's\": 1331, 'ahead': 1332, 'activity': 1333, 'elvin': 1334, 'update': 1335, 'hawker': 1336, 'closed': 1337, 'shops': 1338, 'carry': 1339, 'pubbing': 1340, 'heat': 1341, 'promoting': 1342, 'curious': 1343, 'tuas': 1344, 'pouring': 1345, 'finding': 1346, 'basketball': 1347, 'lying': 1348, 'clubbing': 1349, 'michelle': 1350, 'bet': 1351, '0165460953': 1352, '27': 1353, 'stuffs': 1354, 'booking': 1355, 'enjoying': 1356, 'fox': 1357, 'anyting': 1358, 'store': 1359, 'relationship': 1360, 'brownie': 1361, '7pm': 1362, 'ang': 1363, 'kio': 1364, 'terminal': 1365, 'meal': 1366, \"she'll\": 1367, 'kiat': 1368, 'ugly': 1369, 'gets': 1370, 'crap': 1371, 'joking': 1372, 'ntuc': 1373, 'sultan': 1374, 'wakey': 1375, 'poke': 1376, 'jam': 1377, 'reading': 1378, '24th': 1379, 'won': 1380, '1200': 1381, 'envelope': 1382, 'torquay': 1383, 'ceremony': 1384, 'their': 1385, 'zouk': 1386, 'rag': 1387, 'weird': 1388, 'tony': 1389, 'grandmother': 1390, 'read': 1391, 'belated': 1392, 'submit': 1393, 'lou': 1394, 'further': 1395, 'ring': 1396, 'lend': 1397, 'petey': 1398, 'nic': 1399, 'remembered': 1400, 'favour': 1401, 'golf': 1402, 'malays': 1403, 'emicakes': 1404, 'mistakes': 1405, 'workplace': 1406, 'consider': 1407, 'support': 1408, 'men': 1409, 'mangosteen': 1410, 'shirt': 1411, 'administrative': 1412, 'air': 1413, 'national': 1414, 'married': 1415, 'bill': 1416, 'japanese': 1417, 'restaurant': 1418, \"aren't\": 1419, 'action': 1420, 'move': 1421, 'kill': 1422, 'slp': 1423, 'lie': 1424, 'ter': 1425, 'hah': 1426, 'usually': 1427, 'forms': 1428, 'bye': 1429, 'forever': 1430, 'bukit': 1431, 'namly': 1432, 'keen': 1433, 'instructor': 1434, 's': 1435, 'record': 1436, 'ubi': 1437, 'admit': 1438, 'kid': 1439, 'childish': 1440, 'kiddy': 1441, 'fiona': 1442, 'xie': 1443, 'rule': 1444, 'bathe': 1445, 'fur': 1446, 'superstition': 1447, 'stick': 1448, 'featured': 1449, 'maintenance': 1450, 'technician': 1451, 'riverwalk': 1452, 'dobby': 1453, 'gaught': 1454, 'co': 1455, 'ex': 1456, 'netball': 1457, 'captain': 1458, 'conversation': 1459, 'affected': 1460, 'calrie': 1461, '93517902': 1462, \"it'd\": 1463, 'painful': 1464, 'pictures': 1465, 'formed': 1466, 'grabbed': 1467, 'welcome': 1468, 'singtel': 1469, 'divert': 1470, '1344': 1471, 'voicemail': 1472, '6596400001': 1473, '1800': 1474, '4822800': 1475, '019870491': 1476, 'romny1980': 1477, 'c': 1478, 'lsm1301': 1479, 'photocopy': 1480, 'fridenster': 1481, 'swan': 1482, 'appearing': 1483, 'plane': 1484, 'loving': 1485, '37': 1486, 'degrees': 1487, 'ignore': 1488, '3785738': 1489, 'frankly': 1490, 'direct': 1491, 'others': 1492, 'gossip': 1493, '38': 1494, 'museum': 1495, 'lecturer': 1496, 'list': 1497, 'funan': 1498, 'timer': 1499, 'creps': 1500, 'hereen': 1501, 'yah': 1502, 'bite': 1503, 'scratch': 1504, 'signing': 1505, 'common': 1506, \"people's\": 1507, 'trainee': 1508, 'bungalow': 1509, 'tons': 1510, 'vodka': 1511, 'jacuzzi': 1512, 'baked': 1513, '230': 1514, 'blind': 1515, '78': 1516, '128mb': 1517, 'transcend': 1518, 'jetflash': 1519, 'yourselves': 1520, 'hulk': 1521, 'baru': 1522, 'prepared': 1523, 'vampire': 1524, 'sob': 1525, 'idols': 1526, 'gil': 1527, 'death': 1528, 'sandals': 1529, 'hunks': 1530, 'counting': 1531, 'sharp': 1532, 'honors': 1533, 'christ': 1534, 'manage': 1535, 'meaningless': 1536, 'sardines': 1537, 'tit': 1538, 'bits': 1539, 'bottle': 1540, 'fuji': 1541, 'andrew': 1542, 'cleared': 1543, 'mess': 1544, 'ard': 1545, 'dredz': 1546, 'moses': 1547, 'gp': 1548, 'teasing': 1549, 'difficult': 1550, '200': 1551, 'discussed': 1552, 'parent': 1553, '99853267': 1554, '11am': 1555, 'centrept': 1556, 'ramen': 1557, 'dvd': 1558, 'player': 1559, 'thur': 1560, 'hundreds': 1561, 'locksmiths': 1562, 'available': 1563, 'malaysian': 1564, 'matthew': 1565, 'rocks': 1566, 'ireena': 1567, 'ears': 1568, 'del': 1569, 'lucy': 1570, 'whoever': 1571, 'kreen': 1572, 'cares': 1573, 'ladies': 1574, 'gentleman': 1575, 'china': 1576, 'surf': 1577, 'shorts': 1578, '26th': 1579, \"it'll\": 1580, 'twins': 1581, 'effect': 1582, 'opps': 1583, 'seow': 1584, 'water': 1585, 'pop': 1586, 'bastard': 1587, 'bloody': 1588, 'wtc': 1589, 'fujitsu': 1590, 'honest': 1591, 'makeup': 1592, 'attend': 1593, 'invited': 1594, 'sets': 1595, 'perhaps': 1596, 'texted': 1597, 'jaz': 1598, 'lixia': 1599, 'hammy': 1600, '21st': 1601, 'batch': 1602, '60': 1603, 'learning': 1604, 'yoga': 1605, 'communication': 1606, 'harder': 1607, 'hong': 1608, 'kong': 1609, '96537803': 1610, 'lobang': 1611, 'bank': 1612, 'orhz': 1613, 'colours': 1614, 'regina': 1615, 'corrina': 1616, 'relaxed': 1617, 'boxers': 1618, 'macadamias': 1619, 'chocolates': 1620, 'almonds': 1621, 'accessories': 1622, 'sch': 1623, 'bridge': 1624, 'neo': 1625, 'database': 1626, 'agnes': 1627, 'needles': 1628, 'animals': 1629, 'dividend': 1630, \"shareholder's\": 1631, 'equity': 1632, 'note': 1633, 'sunrise': 1634, 'sommerset': 1635, 'bakkwa': 1636, 'dollar': 1637, 'adverts': 1638, 'tele': 1639, 'market': 1640, 'advert': 1641, 'lead': 1642, 'jay': 1643, 'chou': 1644, 'sen': 1645, 'atm': 1646, 'machine': 1647, 'reason': 1648, 'focus': 1649, 'mainland': 1650, 'silly': 1651, 'arguing': 1652, \"sun's\": 1653, 'hate': 1654, '8332': 1655, '2650': 1656, '6006': 1657, 'audrey': 1658, 'urgent': 1659, 'sound': 1660, 'lazing': 1661, 'low': 1662, 'single': 1663, 'event': 1664, 'frustrated': 1665, 'quality': 1666, 'towels': 1667, 'bare': 1668, 'roller': 1669, 'blades': 1670, 'mike': 1671, 'smoking': 1672, 'skill': 1673, 'tph': 1674, 'fit': 1675, 'under': 1676, '103': 1677, 'mng': 1678, 'discussing': 1679, 'register': 1680, 'gown': 1681, 'measurement': 1682, 'lotion': 1683, 'chauffeur': 1684, 'hahaha': 1685, 'tibs': 1686, 'temporary': 1687, 'promote': 1688, '28th': 1689, 'paying': 1690, 'siam': 1691, 'pad': 1692, 'hit': 1693, 'nail': 1694, 'recruits': 1695, 'intake': 1696, 'assigned': 1697, 'jams': 1698, 'abalone': 1699, 'pissed': 1700, \"i'd\": 1701, 'indian': 1702, 'cup': 1703, 'yummy': 1704, 'quarrelling': 1705, 'smoke': 1706, 'anyways': 1707, 'accepted': 1708, 'arts': 1709, 'miracle': 1710, 'helping': 1711, 'clever': 1712, 'mingle': 1713, 'strawberry': 1714, 'lavender': 1715, 'winery': 1716, 'mick': 1717, 'mem': 1718, 'dining': 1719, 'ziping': 1720, 'supper': 1721, 'carrying': 1722, 'broom': 1723, \"papers'\": 1724, 'perak': 1725, 'hoped': 1726, 'cats': 1727, 'dogs': 1728, 'ran': 1729, '10k': 1730, 'burnt': 1731, 'quarantine': 1732, 'reminds': 1733, 'named': 1734, 'jomis': 1735, 'butt': 1736, 'aches': 1737, \"they'll\": 1738, 'maintain': 1739, 'length': 1740, 'blindfold': 1741, 'writing': 1742, 'comment': 1743, 'haiz': 1744, 'discussion': 1745, 'become': 1746, 'horrible': 1747, 'certain': 1748, 'extent': 1749, 'sort': 1750, 'standard': 1751, 'bookworm': 1752, 'fantasy': 1753, '29': 1754, 'updated': 1755, 'sheet': 1756, 'ethnic': 1757, '93864500': 1758, 'hub': 1759, 'briefing': 1760, 'bristol': 1761, 'les': 1762, 'rudi': 1763, 'eve': 1764, 'snoring': 1765, 'drunk': 1766, 'ink': 1767, 'arty': 1768, 'collages': 1769, 'min': 1770, 'base': 1771, 'color': 1772, 'u2': 1773, 'me？': 1774, 'gosh': 1775, 'embarrassed': 1776, 'realising': 1777, 'noticed': 1778, 'embarrasing': 1779, '97482959': 1780, 'calculus': 1781, 'beneficial': 1782, 'textbook': 1783, 'costs': 1784, '80': 1785, 'primary': 1786, 'toysarus': 1787, 'sells': 1788, 'balloons': 1789, 'penisula': 1790, 'assistant': 1791, 'merchandiser': 1792, 'polo': 1793, 'ralph': 1794, 'colors': 1795, 'farrer': 1796, 'filmed': 1797, 'coloured': 1798, 'aust': 1799, '8th': 1800, 'expected': 1801, 'promised': 1802, 'cindy': 1803, 'overall': 1804, 'score': 1805, 'mid': 1806, \"he'd\": 1807, 'hints': 1808, 'delay': 1809, 'angle': 1810, 'flowers': 1811, 'mohd': 1812, \"sultan's\": 1813, 'taller': 1814, 'probabilty': 1815, 'clips': 1816, 'rules': 1817, 'ended': 1818, 'ten': 1819, 'cs1102': 1820, 'fierce': 1821, 'replacement': 1822, 'metal': 1823, 'preference': 1824, 'agency': 1825, 'product': 1826, 'lagging': 1827, \"weeks'tutorials\": 1828, 'missy': 1829, 'hectic': 1830, 'fail': 1831, 'photostat': 1832, '15pm': 1833, 'yogi': 1834, 'yep': 1835, 'jontin': 1836, 'si': 1837, 'r': 1838, 'imagination': 1839, 'cars': 1840, 'slim': 1841, 'yifeng': 1842, 'mins': 1843, 'gain': 1844, '5kg': 1845, '90853276': 1846, 'grab': 1847, 'opportunities': 1848, 'lexus': 1849, 'es300': 1850, '30k': 1851, 'exciting': 1852, 'prizes': 1853, 'global': 1854, 'kay': 1855, 'cultures': 1856, 'pen': 1857, 'discovered': 1858, \"ng's\": 1859, 'desk': 1860, 'supported': 1861, 'surely': 1862, 'hun': 1863, 'sorted': 1864, 'explain': 1865, 'latest': 1866, \"night's\": 1867, 'knackered': 1868, 'dreading': 1869, 'handsome': 1870, '65': 1871, '97965247': 1872, 'baking': 1873, 'jar': 1874, 'became': 1875, 'chopping': 1876, 'junmei': 1877, 'david': 1878, '6598941248': 1879, 'gower': 1880, 'wales': 1881, 'random': 1882, 'ding': 1883, 'asshole': 1884, 'blacko': 1885, 'wearing': 1886, 'bermuda': 1887, 'garden': 1888, 'noodles': 1889, 'honor': 1890, 'sympathise': 1891, '58': 1892, 'perfume': 1893, 'sim': 1894, 'trouble': 1895, 'muji': 1896, 'finally': 1897, 'laguna': 1898, 'pits': 1899, 'nanyang': 1900, 'polytechnic': 1901, 'physiotherapy': 1902, 'chemistry': 1903, 'peeling': 1904, 'burns': 1905, 'jazz': 1906, 'teacher': 1907, 'dancer': 1908, 'tcs': 1909, 'yan': 1910, 'zi': 1911, 'fill': 1912, 'domain': 1913, 'positive': 1914, 'centrepoint': 1915, '300': 1916, 'yi': 1917, 'stripes': 1918, 'skirt': 1919, \"god's\": 1920, 'sake': 1921, 'freshman': 1922, 'internet': 1923, 'front': 1924, 'river': 1925, 'valley': 1926, 'sape': 1927, 'nama': 1928, 'boleh': 1929, 'kite': 1930, 'typo': 1931, 'lift': 1932, 'tailor': 1933, 'comes': 1934, \"they've\": 1935, 'partner': 1936, 'eurasian': 1937, 'juicer': 1938, 'sardine': 1939, 'n': 1940, 'hold': 1941, 'charger': 1942, 'opera': 1943, 'administrator': 1944, 'quitting': 1945, 'interchange': 1946, 'mad': 1947, 'barking': 1948, 'buses': 1949, 'sydney': 1950, 'shan': 1951, 'ni': 1952, 'rusty': 1953, 'commenting': 1954, 'popularity': 1955, 'spot': 1956, 'piss': 1957, 'damning': 1958, 'recruit': 1959, 'acj': 1960, \"cant't\": 1961, 'flowery': 1962, 'boil': 1963, 'picnic': 1964, 'kahi': 1965, 'response': 1966, 'posted': 1967, 'safti': 1968, 'medic': 1969, 'sarawak': 1970, 'jordon': 1971, 'ourselves': 1972, 'silent': 1973, 'quarantined': 1974, 'holding': 1975, 'bookings': 1976, \"a's\": 1977, 'punish': 1978, 'entering': 1979, 'erp': 1980, 'jogging': 1981, 'claim': 1982, 'vat': 1983, 'admirer': 1984, 'eye': 1985, 'expect': 1986, \"jy's\": 1987, 'singapura': 1988, 'hetic': 1989, 'd': 1990, 'sean': 1991, 'select': 1992, '450': 1993, '470': 1994, 'strength': 1995, 'leading': 1996, 'horse': 1997, 'reduce': 1998, 'mimi': 1999, '0168596707': 2000, 'stays': 2001, 'invisible': 2002, 'ntu': 2003, 'dropped': 2004, 'invite': 2005, 'fow': 2006, 'circulatd': 2007, 'gives': 2008, 'niny': 2009, 'mingfang': 2010, 'cross': 2011, 'met': 2012, 'jocelyn': 2013, 'spoke': 2014, 'fantasia': 2015, 'absolutely': 2016, 'awesome': 2017, 'judges': 2018, 'chosen': 2019, 'balanced': 2020, 'turf': 2021, '800': 2022, 'peril': 2023, 'financial': 2024, 'crisis': 2025, 'lately': 2026, 'ass': 2027, 'ìt': 2028, 'meddlesome': 2029, 'abused': 2030, 'kidding': 2031, 'ming': 2032, 'lun': 2033, 'strange': 2034, '94': 2035, 'pray': 2036, 'protect': 2037, 'wind': 2038, 'blow': 2039, 'stress': 2040, 'twinkle': 2041, 'system': 2042, 'drops': 2043, 'within': 2044, 'cz': 2045, 'directly': 2046, 'lanz': 2047, 'lungs': 2048, 'facial': 2049, 'elfie': 2050, '97615390': 2051, 'surface': 2052, \"fion's\": 2053, 'suggestions': 2054, 'smashed': 2055, 'dent': 2056, 'rock': 2057, 'lesser': 2058, 'phones': 2059, 'chit': 2060, '63383526': 2061, 'noon': 2062, \"week's\": 2063, 'places': 2064, 'regret': 2065, 'inform': 2066, 'nhs': 2067, 'mistake': 2068, 'hospital': 2069, 'terminated': 2070, 'inconvenience': 2071, 'photography': 2072, 'bright': 2073, 'guarding': 2074, 'prosperous': 2075, 'wealth': 2076, 'weiyun': 2077, 'loner': 2078, 'pitched': 2079, 'correct': 2080, '96821456': 2081, 'tazz': 2082, 'pouch': 2083, 'accidents': 2084, 'furthermore': 2085, 'disi': 2086, 'classes': 2087, 'chip': 2088, 'highlighting': 2089, 'yui': 2090, 'economics': 2091, 'aspect': 2092, 'fusion': 2093, 'boss': 2094, 'favourite': 2095, 'crabs': 2096, 'thick': 2097, 'coincidence': 2098, 'jennifer': 2099, 'hudson': 2100, 'phenomenon': 2101, 'wacky': 2102, 'shiny': 2103, 'costume': 2104, 'specially': 2105, 'b7l': 2106, 'jammer': 2107, 'l': 2108, 'india': 2109, \"ira's\": 2110, 'shanghai': 2111, 'somerset': 2112, 'cine': 2113, 'joy': 2114, 'drenched': 2115, \"what're\": 2116, 'chatting': 2117, '11pm': 2118, 'loyong': 2119, 'villa': 2120, 'charged': 2121, '4000': 2122, '32k': 2123, 'myanmar': 2124, 'workers': 2125, 'committee': 2126, 'launching': 2127, 'styles': 2128, 'models': 2129, 'cheng': 2130, 'ting': 2131, 'mummy': 2132, 'farting': 2133, 'mathematics': 2134, 'physics': 2135, 'revise': 2136, 'subject': 2137, 'ill': 2138, 'tonsillitis': 2139, 'laying': 2140, 'christmas': 2141, 'grocery': 2142, '16': 2143, 'drop': 2144, \"spinelli's\": 2145, 'heeren': 2146, 'manager': 2147, 'sounded': 2148, 'pillow': 2149, 'contrary': 2150, 'views': 2151, 'instruction': 2152, 'feels': 2153, 'comfortable': 2154, 'jogged': 2155, 'rounds': 2156, 'legs': 2157, 'personally': 2158, \"wouldn't\": 2159, 'seldom': 2160, 'convince': 2161, 'mention': 2162, 'reaction': 2163, 'wood': 2164, 'renew': 2165, 'private': 2166, 'license': 2167, 'tp': 2168, 'land': 2169, 'eleven': 2170, 'preoccupied': 2171, 'cheer': 2172, 'heh': 2173, 'friendster': 2174, 'replying': 2175, 'bedok': 2176, 'turning': 2177, 'erase': 2178, 'nanxing': 2179, 'da': 2180, 'pang': 2181, 'yong': 2182, 'tau': 2183, 'foo': 2184, 'wishing': 2185, 'rollin': 2186, \"tutorial's\": 2187, 'nearest': 2188, 'flirting': 2189, 'jesslyn': 2190, \"uncle's\": 2191, '91073084': 2192, 'thermometer': 2193, 'spoiled': 2194, 'unwell': 2195, 'xp': 2196, \"eusoff's\": 2197, 'production': 2198, 'embassy': 2199, 'includes': 2200, '1am': 2201, 'tequila': 2202, 'road': 2203, 'strong': 2204, 'sez': 2205, 'arab': 2206, 'buys': 2207, 'heehee': 2208, 'hky': 2209, 'peace': 2210, 'lct': 2211, 'lancome': 2212, 'lcm': 2213, 'foaming': 2214, 'cleansing': 2215, 'gel': 2216, 'combination': 2217, 'dry': 2218, 'pasta': 2219, 'worse': 2220, 'mass': 2221, 'index': 2222, 'potatoes': 2223, 'vegetables': 2224, 'timing': 2225, 'instruct': 2226, '96792371': 2227, 'admission': 2228, \"we've\": 2229, 'spent': 2230, 'meaningful': 2231, 'purple': 2232, 'manners': 2233, 'blessed': 2234, 'happiness': 2235, 'laughter': 2236, 'thai': 2237, 'marshmallow': 2238, 'cz1102': 2239, 'offline': 2240, 'clubroom': 2241, 'saved': 2242, 'pubs': 2243, 'owl': 2244, 'ballot': 2245, 'bake': 2246, \"maxwell's\": 2247, 'storey': 2248, \"market's\": 2249, 'stalls': 2250, 'smith': 2251, 'opened': 2252, 'bodynits': 2253, 'bra': 2254, 'shitty': 2255, 'renovated': 2256, 'facilities': 2257, 'easy': 2258, 'considered': 2259, 'branded': 2260, 'among': 2261, 'thumb': 2262, '64mb': 2263, '28': 2264, 'second': 2265, 'math': 2266, 'surname': 2267, 'poem': 2268, 'wonder': 2269, 'woking': 2270, 'planned': 2271, 'slowly': 2272, 'fated': 2273, 'staff': 2274, 'corporation': 2275, 'recorded': 2276, 'letter': 2277, 'srs': 2278, 'payment': 2279, 'kote': 2280, 'maxy': 2281, \"pest's\": 2282, '3pm': 2283, 'committees': 2284, 'comm': 2285, 'venue': 2286, 'define': 2287, 'dial': 2288, 'user': 2289, 'id': 2290, 'colgate': 2291, 'wrks': 2292, 'difference': 2293, 'rested': 2294, 'match': 2295, 'grounded': 2296, 'tasty': 2297, 'configured': 2298, 'lonely': 2299, 'tubes': 2300, 'newsweek': 2301, '42': 2302, 'sharing': 2303, 'shocked': 2304, 'bleach': 2305, 'suying': 2306, 'occupy': 2307, 'wooden': 2308, 'aluminium': 2309, 'march': 2310, 'fran': 2311, 'exeter': 2312, 'tina': 2313, 'transport': 2314, 'invites': 2315, '7th': 2316, '02': 2317, '34': 2318, 'seemed': 2319, 'slice': 2320, 'ger16': 2321, 'carfinal1': 2322, 'clp': 2323, 'addidas': 2324, 'shoes': 2325, 'irregardless': 2326, 'seniors': 2327, 'sakae': 2328, 'goodies': 2329, 'emporium': 2330, 'create': 2331, 'depend': 2332, 'odd': 2333, '99876452': 2334, '<end>': 2335, 'devin': 2336, '13': 2337, '14': 2338, 'liling': 2339, 'chen': 2340, 'clearing': 2341, 'academic': 2342, 'benefits': 2343, 'answered': 2344, 'st1232': 2345, 'havoc': 2346, 'vain': 2347, 'walked': 2348, 'serious': 2349, 'anywehre': 2350, \"you've\": 2351, 'hammer': 2352, 'hits': 2353, 'concern': 2354, \"he'll\": 2355, 'beat': 2356, 'membership': 2357, 'rot': 2358, 'pj': 2359, 'responding': 2360, 'sh': 2361, 'objection': 2362, 'backout': 2363, 'tennis': 2364, 'dieting': 2365, 'emailed': 2366, 'attending': 2367, 'mpsh': 2368, 'extend': 2369, 'tip': 2370, 'arr': 2371, 'derel': 2372, 'retrieve': 2373, 'yin': 2374, 'gloating': 2375, 'wing': 2376, 'somemore': 2377, 'network': 2378, 'causing': 2379, 'slow': 2380, 'josh': 2381, 'reception': 2382, 'teach': 2383, 'machines': 2384, 'bird': 2385, 'tournament': 2386, 'lucky': 2387, 'rich': 2388, 'wife': 2389, 'tray': 2390, 'jade': 2391, 'barmed': 2392, 'advertisement': 2393, 'mohammad': 2394, 'consolidating': 2395, 'responses': 2396, 'responds': 2397, 'traffic': 2398, 'full': 2399, '00': 2400, 'lt24': 2401, \"time's\": 2402, 'moboy': 2403, 'happening': 2404, 'following': 2405, 'innocent': 2406, 'pure': 2407, 'augest': 2408, 'lt32': 2409, 'formal': 2410, 'arrangement': 2411, 'realistic': 2412, 'wins': 2413, 'saimee': 2414, 'outsider': 2415, '1400': 2416, 'jame': 2417, 'seed': 2418, 'shucks': 2419, 'replace': 2420, 'cca': 2421, '1245': 2422, 'bonds': 2423, 'totally': 2424, 'detest': 2425, 'conscious': 2426, 'factory': 2427, 'outlet': 2428, 'mb': 2429, 'opening': 2430, 'terok': 2431, 'secret': 2432, 'trg': 2433, 'informed': 2434, 'played': 2435, 'insights': 2436, 'gained': 2437, 'safe': 2438, 'commons': 2439, 'publicity': 2440, 'xuhui': 2441, 'ok，see': 2442, 'hide': 2443, 'classmate': 2444, 'kai': 2445, 'qin': 2446, 'bahru': 2447, 'trim': 2448, 'topshop': 2449, 'ridge': 2450, 'wide': 2451, 'plans': 2452, 'aljunied': 2453, 'dumpling': 2454, 'contacting': 2455, '225': 2456, '375': 2457, 'url': 2458, 'exhibition': 2459, 'noel': 2460, 'review': 2461, 'geleck': 2462, 'queen': 2463, 'officially': 2464, 'dearies': 2465, '93466348': 2466, 'knit': 2467, 'sweater': 2468, 'materials': 2469, 'calender': 2470, 'realized': 2471, 'overprotective': 2472, 'treated': 2473, 'menghong': 2474, 'squash': 2475, 'ours': 2476, 'causeway': 2477, 'document': 2478, \"friends'\": 2479, 'lancaster': 2480, 'extreme': 2481, 'curriculum': 2482, 'centro': 2483, 'tdy': 2484, 'smooth': 2485, 'dna': 2486, 'messaging': 2487, 'police': 2488, 'irritating': 2489, \"wasn't\": 2490, 'phoned': 2491, \"your's\": 2492, 'petty': 2493, 'assessment': 2494, 'black': 2495, 'jack': 2496, 'boredom': 2497, 'recommendations': 2498, 'explicit': 2499, 'terence': 2500, 'aik': 2501, 'randy': 2502, 'awkward': 2503, 'sat': 2504, 'kingshead': 2505, 'lover': 2506, 'cedes': 2507, 'lame': 2508, 'din': 2509, 'joins': 2510, 'harry': 2511, 'potter': 2512, '33': 2513, 'photograph': 2514, \"kid's\": 2515, 'bathed': 2516, 'stinky': 2517, 'housewife': 2518, 'ellen': 2519, 'rays': 2520, 'leaves': 2521, 'worries': 2522, 'bay': 2523, 'sleepy': 2524, 'belt': 2525, 'canvas': 2526, 'cloth': 2527, 'fault': 2528, 'starhub': 2529, 'minimum': 2530, 'sian': 2531, 'timetable': 2532, 'doctor': 2533, 'disease': 2534, 'boggy': 2535, 'woods': 2536, 'tried': 2537, 'meijun': 2538, 'acceptable': 2539, 'straightaway': 2540, 'contraction': 2541, 'published': 2542, 'marketing': 2543, 'jenniffer': 2544, 'peep': 2545, 'zoo': 2546, 'celebrating': 2547, 'birth': 2548, 'attract': 2549, 'unrestricted': 2550, 'electives': 2551, 'high': 2552, \"'okay'\": 2553, 'charges': 2554, 'esther': 2555, 'failed': 2556, 'roughly': 2557, 'gift': 2558, 'stinge': 2559, 'knock': 2560, '530pm': 2561, 'huiqi': 2562, 'farewell': 2563, 'marina': 2564, 'mt': 2565, 'coca': 2566, 'spare': 2567, 'surprise': 2568, 'right？': 2569, 'aged': 2570, 'giving': 2571, 'shame': 2572, 'yogasana': 2573, 'such': 2574, 'ay': 2575, 'worked': 2576, 'daytime': 2577, 'dumb': 2578, 'funky': 2579, 'sam': 2580, 'checking': 2581, 'tanjong': 2582, 'pagar': 2583, 'tiffany': 2584, 'gek1005': 2585, 'cherish': 2586, 'webpage': 2587, 'language': 2588, 'television': 2589, 'clean': 2590, 'temporarily': 2591, '100': 2592, 'loss': 2593, 'imperialmusic': 2594, 'listening': 2595, 'weirdest': 2596, 'track': 2597, '“leafcutter': 2598, 'john”': 2599, 'insects': 2600, 'molested': 2601, 'plumbing': 2602, 'remixed': 2603, 'evil': 2604, 'acid': 2605, 'jurong': 2606, 'starting': 2607, 'flu': 2608, 'running': 2609, 'sorta': 2610, 'graphic': 2611, 'design': 2612, 'ticket': 2613, 'crown': 2614, '91074867': 2615, 'administration': 2616, \"chinatown's\": 2617, 'cleaning': 2618, 'now，are': 2619, 'newquay': 2620, 'postcard': 2621, 'higher': 2622, 'xroom': 2623, \"joan's\": 2624, 'guinea': 2625, 'pigs': 2626, 'genting': 2627, 'smallville': 2628, 'dozing': 2629, \"grandma's\": 2630, 'grandma': 2631, 'none': 2632, 'nowhere': 2633, 'h': 2634, 'access': 2635, 'vpn': 2636, 'download': 2637, 'stella': 2638, 'fixed': 2639, 'brunswick': 2640, 'alannan': 2641, 'hill': 2642, 'income': 2643, 'chijmes': 2644, 'simple': 2645, 'groceries': 2646, 'cook': 2647, 'luckily': 2648, 'enlarge': 2649, 'creative': 2650, 'queue': 2651, 'fitness': 2652, 'roadshow': 2653, 'six': 2654, 'goodie': 2655, 'bags': 2656, 'luckyspin': 2657, 'junction': 2658, '2003': 2659, '63366822': 2660, 'reminder': 2661, 'force': 2662, 'muaks': 2663, 'celine': 2664, '6590957823': 2665, '0164330931': 2666, 'yunny': 2667, 'appointment': 2668, 'opens': 2669, 'monkees': 2670, 'howdy': 2671, 'sausage': 2672, 'jen': 2673, 'usual': 2674, 'tours': 2675, 'kisses': 2676, 'weekday': 2677, 'kitten': 2678, 'mel': 2679, 'owes': 2680, 'control': 2681, 'diet': 2682, 'drag': 2683, 'zepol': 2684, 'frog': 2685, 'capital': 2686, 'kwang': 2687, 'chow': 2688, '5th': 2689, 'vacancy': 2690, 'bruce': 2691, 'almighty': 2692, 'asp': 2693, 'jsp': 2694, 'thailand': 2695, 'vcd': 2696, 'samurai': 2697, 'zping': 2698, 'upstairs': 2699, 'cherry': 2700, 'practice': 2701, 'talked': 2702, 'jon': 2703, 'spain': 2704, 'dinero': 2705, '000pes': 2706, '£48': 2707, 'tb': 2708, 'nagging': 2709, '12pm': 2710, 'ample': 2711, 'lorong': 2712, 'medicine': 2713, 'level': 2714, \"jac's\": 2715, 'whackers33': 2716, 'darn': 2717, 'dom': 2718, 'indians': 2719, 'shexy': 2720, 'kick': 2721, 'boxing': 2722, 'fully': 2723, 'model': 2724, 'shoe': 2725, '221': 2726, 'boon': 2727, 'lay': 2728, 'nokia': 2729, '7250': 2730, 'trade': 2731, '719': 2732, 'configure': 2733, 'piece': 2734, 'postings': 2735, 'sing': 2736, 'cafe': 2737, 'cartel': 2738, 'topic': 2739, 'covering': 2740, '97856124': 2741, 'fen': 2742, 'mistress': 2743, \"kua's\": 2744, 'knew': 2745, 'cdd': 2746, 'reported': 2747, 'immediately': 2748, 'against': 2749, 'compliance': 2750, 'realize': 2751, 'keeping': 2752, 'exhilarating': 2753, '23f': 2754, 'arrived': 2755, 'tom': 2756, 'moisturise': 2757, 'rub': 2758, 'circular': 2759, 'motion': 2760, 'tone': 2761, 'jelly': 2762, 'onto': 2763, 'tap': 2764, 'lala': 2765, 'zip': 2766, 'first\\u3000and': 2767, 'colourful': 2768, 'map': 2769, 'printer': 2770, 'huge': 2771, 'favor': 2772, 'mi': 2773, 'modules': 2774, 'thicker': 2775, 'dropping': 2776, 'adress': 2777, '18th': 2778, 'legalized': 2779, 'bless': 2780, 'raffles': 2781, 'sunburn': 2782, 'loan': 2783, 'dan': 2784, 'suit': 2785, 'confident': 2786, 'hopefully': 2787, 'durian': 2788, 'pastry': 2789, 'pestering': 2790, 'jerk': 2791, 'wishes': 2792, 'levels': 2793, 'sunperks': 2794, '1627': 2795, 'promotion': 2796, 'remove': 2797, 'spoken': 2798, 'js': 2799, 'reunion': 2800, 'tiredness': 2801, 'draws': 2802, 'across': 2803, 'fade': 2804, 'flexibility': 2805, 'soul': 2806, 'begin': 2807, 'enter': 2808, 'dreamland': 2809, 'rv': 2810, 'ages': 2811, 'roads': 2812, 'pity': 2813, 'sine': 2814, 'melting': 2815, '132': 2816, '135': 2817, \"'yo\": 2818, 'yo': 2819, \"up'\": 2820, 'unsure': 2821, 'helped': 2822, '11th': 2823, 'checkup': 2824, 'competition': 2825, 'macaroni': 2826, 'biscuits': 2827, 'junior': 2828, 'january': 2829, \"ben's\": 2830, \"wa's\": 2831, 'north': 2832, '96473920': 2833, '47': 2834, 'touch': 2835, 'grave': 2836, 'dug': 2837, 'circuit': 2838, 'awards': 2839, 'petition': 2840, 'william': 2841, 'hung': 2842, 'nopez': 2843, 'aishya': 2844, 'terrible': 2845, 'combat': 2846, 'received': 2847, 'brown': 2848, 'eymani': 2849, 'frequent': 2850, 'headache': 2851, 'yunñy': 2852, 'wonderful': 2853, 'remain': 2854, 'jìayin': 2855, 'juli': 2856, 'abandon': 2857, 'jc': 2858, 'kilo': 2859, 'officers': 2860, 'memorable': 2861, \"huixin's\": 2862, 'warming': 2863, 'blk': 2864, '517': 2865, 'law': 2866, 'fatter': 2867, 'environment': 2868, 'hamsters': 2869, 'teaching': 2870, 'korean': 2871, 'recommend': 2872, 'scold': 2873, 'encouraging': 2874, 'listened': 2875, 'plaid': 2876, 'album': 2877, 'hilarious': 2878, 'braindance': 2879, 'compilation': 2880, \"aphex's\": 2881, 'label': 2882, 'installing': 2883, 'wireless': 2884, 'sensitive': 2885, 'cancellation': 2886, 'forfeited': 2887, 'crumpler': 2888, \"en's\": 2889, 'suspect': 2890, 'seven': 2891, 'thirty': 2892, 'fountain': 2893, 'sanur': 2894, 'separated': 2895, 'ready': 2896, 'peach': 2897, 'tastes': 2898, 'lush': 2899, 'digi': 2900, 'mac': 2901, 'muffin': 2902, '8310': 2903, 'nsf': 2904, 'poorest': 2905, 'boys': 2906, 'roaming': 2907, 'trial': 2908, \"m1's\": 2909, 'alert': 2910, 'www': 2911, 'log': 2912, 'screen': 2913, 'expanding': 2914, 'sideway': 2915, 'remedy': 2916, 'definitely': 2917, 'confide': 2918, 'gossiping': 2919, 'drawer': 2920, 'camera': 2921, 'beneath': 2922, 'pale': 2923, \"meijun's\": 2924, 'share': 2925, 'crepes': 2926, 'rude': 2927, 'lea，yes': 2928, 'wu': 2929, 'jian': 2930, 'dao': 2931, 'sneaks': 2932, 'perfectly': 2933, 'disappointed': 2934, 'parade': 2935, 'foam': 2936, 'avoid': 2937, 'tells': 2938, '5419814': 2939, 'sir': 2940, 'reachd': 2941, 'knack': 2942, 'ing': 2943, 'knocking': 2944, 'qet': 2945, 'giro': 2946, 'mohmd': 2947, 'cover': 2948, \"anyone's\": 2949, 'jez': 2950, 'scattered': 2951, 'everywhere': 2952, 'zheng': 2953, 'fix': 2954, 'sales': 2955, 'spinelli': 2956, 'oreo': 2957, 'fat': 2958, 'square': 2959, 'drain': 2960, 'cycling': 2961, 'campus': 2962, 'panjang': 2963, 'toaster': 2964, 'jolene': 2965, \"there'll\": 2966, 'asap': 2967, 'spread': 2968, 'dirty': 2969, 'responsible': 2970, 'academy': 2971, 'freshmen': 2972, 'ave': 2973, 'timah': 2974, 'clinic': 2975, 'annie': 2976, 'barbecue': 2977, 'civilisation': 2978, 'grabbing': 2979, 'ice': 2980, 'bun': 2981, 'bone': 2982, 'tooth': 2983, 'ache': 2984, 'plenty': 2985, 'write': 2986, 'profiles': 2987, 'receptionist': 2988, 'earrings': 2989, 'suggest': 2990, 'sizzler': 2991, 's56': 2992, 'glad': 2993, 'guesses': 2994, 'importantly': 2995, 'regrets': 2996, 'gstring': 2997, 'roman': 2998, 'font': 2999, 'spacing': 3000, 'overnight': 3001, 'ocean': 3002, 'rd': 3003, 'bug': 3004, 'irritate': 3005, 'cry': 3006, 'diarrhoea': 3007, 'spore': 3008, 'needed': 3009, 'surpass': 3010, 'stairs': 3011, 'knees': 3012, 'stopping': 3013, 'homework': 3014, 'flight': 3015, 'snatch': 3016, 'sticks': 3017, 'sold': 3018, 'unix': 3019, 'unic': 3020, 'messy': 3021, 'jiayin': 3022, \"wawa's\": 3023, '53': 3024, 'click': 3025, 'view': 3026, \"modules'\": 3027, 'cityhall': 3028, 'organise': 3029, 'vesak': 3030, 'activities': 3031, 'stricter': 3032, 'although': 3033, 'conditioning': 3034, 'cushioned': 3035, 'chair': 3036, \"customer's\": 3037, 'ignoring': 3038, 'aim': 3039}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OF9G_a1Yyf0L","executionInfo":{"status":"ok","timestamp":1616516045215,"user_tz":-330,"elapsed":1484,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"015baab4-d11b-473a-a6eb-294841878a6c"},"source":["from joblib import dump, load\n","decoder_embedding=load('/content/decoder_embedding2.joblib')\n","print(decoder_embedding.shape)\n","encoder_embedding=load('/content/encoder_embedding1.joblib')\n","print(encoder_embedding.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3040, 300)\n","(3702, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jElxJioGoC_2"},"source":["class Encoder(tf.keras.Model):\n","    '''\n","    Encoder model -- That takes a input sequence and returns output sequence\n","    '''\n","\n","    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n","        self.inp_vocab_size=inp_vocab_size\n","        self.embedding_size=embedding_size\n","        self.lstm_size=lstm_size\n","        self.input_length=input_length\n","\n","        #Initialize Embedding layer\n","\n","        #Intialize Encoder LSTM layer\n","        super().__init__()\n","        self.Embedding_Layer=tf.keras.layers.Embedding(input_dim=self.inp_vocab_size,output_dim=self.embedding_size,input_length=input_length,mask_zero=True,name=\"Encoder_Embedding\",weights=[encoder_embedding])\n","        self.LSTM_Layer=tf.keras.layers.LSTM(self.lstm_size,return_state=True,return_sequences=True,name=\"Encoder_LSTM\")\n","\n","    def call(self,input_sequence,states):\n","      '''\n","          This function takes a sequence input and the initial states of the encoder.\n","          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n","          returns -- All encoder_outputs, last time steps hidden and cell state\n","      '''\n","      input_embedd=self.Embedding_Layer(input_sequence)\n","      self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.LSTM_Layer(input_embedd)\n","     \n","      return self.lstm_output,self.lstm_state_h,self.lstm_state_c\n","\n","    \n","    def initialize_states(self,batch_size):\n","      '''\n","      Given a batch size it will return intial hidden state and intial cell state.\n","      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n","      '''\n","      intial_hidden_state=np.zeros((batch_size,self.lstm_size))\n","      intial_cell_state=np.zeros((batch_size,self.lstm_size))\n","      return intial_hidden_state,intial_cell_state"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlSYbBfbol04"},"source":["class Attention(tf.keras.layers.Layer):\n","  '''\n","    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n","  '''\n","  def __init__(self,scoring_function, att_units):\n","    self.scoring_function=scoring_function\n","    self.att_units=att_units \n","    super().__init__()\n"," \n","    # Please go through the reference notebook and research paper to complete the scoring functions\n"," \n","    if self.scoring_function=='dot':\n","      # Intialize variables needed for Dot score function here\n","      pass\n"," \n","      \n","      \n","    if scoring_function == 'general':\n","      # Intialize variables needed for General score function here\n","      self.W=tf.keras.layers.Dense(att_units)\n","    elif scoring_function == 'concat':\n","      # Intialize variables needed for Concat score function here\n","      self.W1 = tf.keras.layers.Dense(att_units)\n","      self.W2 = tf.keras.layers.Dense(att_units)\n","      self.V = tf.keras.layers.Dense(1)\n","  \n","  \n","  def call(self,decoder_hidden_state,encoder_output):\n","    '''\n","      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n","      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n","        Multiply the score function with your encoder_outputs to get the context vector.\n","        Function returns context vector and attention weights(softmax - scores)\n","    '''\n","    \n","    if self.scoring_function == 'dot':\n","        # Implement Dot score function here\n","        \n","        \n","        scoring=tf.matmul(encoder_output,tf.expand_dims(decoder_hidden_state,axis=-1))\n","        \n","        attention_weight=tf.nn.softmax(scoring,axis=1)\n","        \n","        context_vector=attention_weight*encoder_output\n","        context_vector=tf.reduce_sum(context_vector,axis=1)\n","        return context_vector,attention_weight\n","              \n","        \n","        \n","        \n"," \n","        \n","    elif self.scoring_function == 'general':\n","        # Implement General score function here\n","        \n","        score=tf.matmul(self.W(encoder_output),tf.expand_dims(decoder_hidden_state,axis=-1))\n","        attention_weight=tf.nn.softmax(score,axis=1)\n","        context_vector=attention_weight*encoder_output\n","        context_vector=tf.reduce_sum(context_vector,axis=1)\n","        return context_vector,attention_weight\n","    \n","    elif self.scoring_function == 'concat':\n","        # Implement General score function here\n","        score = self.V(tf.nn.tanh(self.W1(encoder_output) + self.W2(tf.expand_dims(decoder_hidden_state,axis=1))))\n","        attention_weight=tf.nn.softmax(score,axis=1)\n","        context_vector=attention_weight*encoder_output\n","        context_vector=tf.reduce_sum(context_vector,axis=1)\n","        return context_vector,attention_weight"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eGwYdfUop92"},"source":["class OneStepDecoder(tf.keras.Model):\n","  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n","\n","      # Initialize decoder embedding layer, LSTM and any other objects needed\n","      self.tar_vocab_size=tar_vocab_size\n","      self.embedding_dim=embedding_dim\n","      self.input_length=input_length\n","      self.dec_units=dec_units\n","      self.score_fun=score_fun\n","      self.att_units=att_units\n","      super().__init__()\n","      self.DEmbedding=tf.keras.layers.Embedding(input_dim=self.tar_vocab_size,output_dim=self.embedding_dim,input_length=self.input_length,mask_zero=True,name=\"Decoder_Embedding\", trainable=False,weights=[decoder_embedding])\n","      self.DLSTM_Layer=tf.keras.layers.LSTM(self.dec_units,return_state=True,return_sequences=True,name=\"Encoder_LSTM\")\n","      self.full_connected=tf.keras.layers.Dense(self.tar_vocab_size)\n","      self.attention=Attention(self.score_fun,self.att_units)\n","\n","\n","\n","\n","  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n","    '''\n","        One step decoder mechanisim step by step:\n","      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n","      B. Using the encoder_output and decoder hidden state, compute the context vector.\n","      C. Concat the context vector with the step A output\n","      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n","      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n","      F. Return the states from step D, output from Step E, attention weights from Step -B\n","    '''\n","    #step-A\n","    output=self.DEmbedding(input_to_decoder)\n","    #step-B\n","   \n","    context_vector,attention_weights=self.attention(state_h,encoder_output)\n","    #step-C\n","    concat=tf.concat([tf.expand_dims(context_vector,1),output],axis=-1)\n","    #step-D\n","    decoder_output,hidden_states,cell_states=self.DLSTM_Layer(concat,initial_state=[state_h,state_c])\n","    decoder_output=tf.reshape(decoder_output,(-1,decoder_output.shape[2]))\n","    output=self.full_connected(decoder_output)\n","    return output,hidden_states,cell_states,attention_weights,context_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bI3GjxvxouY9"},"source":["class Decoder(tf.keras.Model):\n","    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n","      #Intialize necessary variables and create an object from the class onestepdecoder\n","      self.out_vocab_size=out_vocab_size\n","      self.embedding_dim=embedding_dim\n","      self.input_length=input_length\n","      self.dec_units=dec_units\n","      self.score_fun=score_fun\n","      self.att_units=att_units\n","      super().__init__()\n","      self.onestepdecoder=OneStepDecoder(self.out_vocab_size, self.embedding_dim, self.input_length, self.dec_units ,self.score_fun ,self.att_units)\n","\n","\n","     \n","    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n","\n","        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n","        #Create a tensor array as shown in the reference notebook\n","        \n","        #Iterate till the length of the decoder input\n","            # Call onestepdecoder for each token in decoder_input\n","            # Store the output in tensorarray\n","        # Return the tensor array\n","        \n","        all_outputs=tf.TensorArray(tf.float32,size=tf.shape(input_to_decoder)[1],name=\"output_arrays\")\n","      \n","        \n","        for timestep in range(tf.shape(input_to_decoder)[1]):\n","            output,decoder_hidden_state,decoder_cell_state,_,_=self.onestepdecoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n","            all_outputs=all_outputs.write(timestep,output)\n","            \n","        all_outputs=tf.transpose(all_outputs.stack(),[1,0,2])\n","        return all_outputs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKZnv-6upAIn"},"source":["\n","class encoder_decoder(tf.keras.Model):\n","    def __init__(self,embedding_size,lstm_size,input_length,decoder_input_length,dec_units ,score_fun ,att_units, batch_size):\n","        #Intialize objects from encoder decoder\n","        super().__init__()\n","        self.encoder=Encoder(len(encoder_vocabluary)+1,embedding_size,lstm_size,input_length)\n","        self.decoder=Decoder(len(decoder_vocabluary)+1,embedding_size, decoder_input_length, dec_units ,score_fun ,att_units)\n","        self.batch_size= batch_size\n","    def call(self,data):\n","        #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n","        # Decoder initial states are encoder final states, Initialize it accordingly\n","        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n","        # return the decoder output\n","        input_,target_sentences = data[0], data[1]\n","        initial_state= self.encoder.initialize_states(self.batch_size)\n","        encoder_output,state_h,state_c=self.encoder(input_,initial_state)\n","        output=self.decoder(target_sentences,encoder_output, state_h, state_c)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9m3U5OBHpEht"},"source":["def custom_lossfunction(targets,logits):\n","\n","  # Custom loss function that will not consider the loss for padded zeros.\n","  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n","   \n","   loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","   mask = tf.math.logical_not(tf.math.equal(targets, 0))\n","   loss_ = loss_object(targets, logits)\n","\n","   mask = tf.cast(mask, dtype=loss_.dtype)\n","   loss_ *= mask\n","\n","   return tf.reduce_mean(loss_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3MBUT2kqJsp"},"source":["class Dataset:\n","    def __init__(self, data, tknizer_ita, tknizer_eng, max_len,max_len1):\n","        self.encoder_inps = data['SMS_TEXT'].values\n","        self.decoder_inps = data['ENGLISH_INPUT'].values\n","        self.decoder_outs = data['ENGLISH_OUTPUT'].values\n","        self.tknizer_eng = tknizer_eng\n","        self.tknizer_ita = tknizer_ita\n","        self.max_len = max_len\n","        self.max_len1=max_len1\n"," \n","    def __getitem__(self, i):\n","        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n","        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n","        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n"," \n","        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n","        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len1, dtype='int32', padding='post')\n","        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len1, dtype='int32', padding='post')\n","        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n"," \n","    def __len__(self): # your model.fit_gen requires this function\n","        return len(self.encoder_inps)\n"," \n","    \n","class Dataloder(tf.keras.utils.Sequence):    \n","    def __init__(self, dataset, batch_size=1):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.indexes = np.arange(len(self.dataset.encoder_inps))\n"," \n"," \n","    def __getitem__(self, i):\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        data = []\n","        for j in range(start, stop):\n","            data.append(self.dataset[j])\n"," \n","        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n","        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n","        return tuple([[batch[0],batch[1]],batch[2]])\n"," \n","    def __len__(self):  # your model.fit_gen requires this function\n","        return len(self.indexes) // self.batch_size\n"," \n","    def on_epoch_end(self):\n","        self.indexes = np.random.permutation(self.indexes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":904},"id":"Gkb-H6edqS22","executionInfo":{"status":"error","timestamp":1616516435546,"user_tz":-330,"elapsed":297185,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"2bacfef3-a200-4f17-8730-f957436e9298"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,256,38,39,256,'concat',256,64)\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 30s 710ms/step - loss: 2.5480 - val_loss: 2.3325\n","Epoch 2/40\n","30/30 [==============================] - 20s 672ms/step - loss: 2.2365 - val_loss: 2.2937\n","Epoch 3/40\n","30/30 [==============================] - 19s 623ms/step - loss: 2.1629 - val_loss: 2.2443\n","Epoch 4/40\n","30/30 [==============================] - 19s 645ms/step - loss: 2.0915 - val_loss: 2.1800\n","Epoch 5/40\n","30/30 [==============================] - 19s 631ms/step - loss: 1.9005 - val_loss: 2.1036\n","Epoch 6/40\n","30/30 [==============================] - 19s 624ms/step - loss: 1.8547 - val_loss: 2.0614\n","Epoch 7/40\n","30/30 [==============================] - 19s 635ms/step - loss: 1.7162 - val_loss: 1.9904\n","Epoch 8/40\n","30/30 [==============================] - 19s 635ms/step - loss: 1.5961 - val_loss: 1.9626\n","Epoch 9/40\n","30/30 [==============================] - 19s 640ms/step - loss: 1.4634 - val_loss: 1.9375\n","Epoch 10/40\n","30/30 [==============================] - 19s 622ms/step - loss: 1.3497 - val_loss: 1.9579\n","Epoch 11/40\n","30/30 [==============================] - 19s 619ms/step - loss: 1.2098 - val_loss: 1.9503\n","Epoch 12/40\n","30/30 [==============================] - 19s 629ms/step - loss: 1.0310 - val_loss: 1.9951\n","Epoch 13/40\n","30/30 [==============================] - 19s 617ms/step - loss: 0.9173 - val_loss: 2.0186\n","Epoch 14/40\n","13/30 [============>.................] - ETA: 10s - loss: 0.7592"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-3822bf53cadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hbdIa6I77k_H","executionInfo":{"status":"error","timestamp":1616517022833,"user_tz":-330,"elapsed":568728,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"6e0af157-cd02-4074-a523-d90de94b6278"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,256,38,39,256,'concat',256,64)\n","optimizer = tf.keras.optimizers.Adam()\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 28s 678ms/step - loss: 2.7253 - val_loss: 2.3231\n","Epoch 2/40\n","30/30 [==============================] - 18s 584ms/step - loss: 2.3340 - val_loss: 2.3000\n","Epoch 3/40\n","30/30 [==============================] - 17s 582ms/step - loss: 2.2256 - val_loss: 2.2845\n","Epoch 4/40\n","30/30 [==============================] - 18s 600ms/step - loss: 2.2436 - val_loss: 2.2762\n","Epoch 5/40\n","30/30 [==============================] - 18s 598ms/step - loss: 2.2103 - val_loss: 2.2775\n","Epoch 6/40\n","30/30 [==============================] - 17s 571ms/step - loss: 2.1695 - val_loss: 2.2658\n","Epoch 7/40\n","30/30 [==============================] - 17s 578ms/step - loss: 2.1364 - val_loss: 2.2475\n","Epoch 8/40\n","30/30 [==============================] - 18s 585ms/step - loss: 2.1521 - val_loss: 2.2330\n","Epoch 9/40\n","30/30 [==============================] - 18s 589ms/step - loss: 2.1376 - val_loss: 2.2171\n","Epoch 10/40\n","30/30 [==============================] - 17s 577ms/step - loss: 2.1100 - val_loss: 2.1884\n","Epoch 11/40\n","30/30 [==============================] - 18s 586ms/step - loss: 2.0598 - val_loss: 2.1641\n","Epoch 12/40\n","30/30 [==============================] - 17s 578ms/step - loss: 2.0565 - val_loss: 2.1379\n","Epoch 13/40\n","30/30 [==============================] - 18s 592ms/step - loss: 1.9954 - val_loss: 2.1122\n","Epoch 14/40\n","30/30 [==============================] - 18s 584ms/step - loss: 1.9713 - val_loss: 2.0876\n","Epoch 15/40\n","30/30 [==============================] - 18s 582ms/step - loss: 1.9156 - val_loss: 2.0666\n","Epoch 16/40\n","30/30 [==============================] - 18s 592ms/step - loss: 1.9081 - val_loss: 2.0420\n","Epoch 17/40\n","30/30 [==============================] - 17s 580ms/step - loss: 1.8675 - val_loss: 2.0119\n","Epoch 18/40\n","30/30 [==============================] - 18s 607ms/step - loss: 1.7890 - val_loss: 1.9762\n","Epoch 19/40\n","30/30 [==============================] - 17s 583ms/step - loss: 1.7257 - val_loss: 1.9476\n","Epoch 20/40\n","30/30 [==============================] - 17s 581ms/step - loss: 1.6969 - val_loss: 1.9169\n","Epoch 21/40\n","30/30 [==============================] - 18s 587ms/step - loss: 1.6663 - val_loss: 1.8892\n","Epoch 22/40\n","30/30 [==============================] - 17s 571ms/step - loss: 1.6405 - val_loss: 1.8636\n","Epoch 23/40\n","30/30 [==============================] - 18s 590ms/step - loss: 1.5910 - val_loss: 1.8377\n","Epoch 24/40\n","30/30 [==============================] - 18s 600ms/step - loss: 1.5523 - val_loss: 1.8478\n","Epoch 25/40\n","30/30 [==============================] - 18s 608ms/step - loss: 1.5586 - val_loss: 1.8022\n","Epoch 26/40\n","30/30 [==============================] - 18s 584ms/step - loss: 1.4842 - val_loss: 1.8015\n","Epoch 27/40\n","30/30 [==============================] - 19s 616ms/step - loss: 1.4484 - val_loss: 1.7971\n","Epoch 28/40\n","30/30 [==============================] - 17s 569ms/step - loss: 1.4012 - val_loss: 1.7687\n","Epoch 29/40\n","30/30 [==============================] - 17s 583ms/step - loss: 1.3490 - val_loss: 1.7535\n","Epoch 30/40\n","30/30 [==============================] - 17s 580ms/step - loss: 1.3350 - val_loss: 1.7605\n","Epoch 31/40\n","30/30 [==============================] - 17s 580ms/step - loss: 1.2760 - val_loss: 1.7282\n","Epoch 32/40\n","16/30 [===============>..............] - ETA: 8s - loss: 1.2680"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-3d5304a630e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0lSUORU9dIh","executionInfo":{"status":"ok","timestamp":1616517837095,"user_tz":-330,"elapsed":9299,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"d9da07c2-940e-43bb-ca07-3402b9dbfaf1"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,100,38,39,100,'concat',100,64)\n","optimizer = tf.keras.optimizers.Adam()\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 28s 671ms/step - loss: 2.9386 - val_loss: 2.3748\n","Epoch 2/40\n","30/30 [==============================] - 19s 621ms/step - loss: 2.2915 - val_loss: 2.3211\n","Epoch 3/40\n","30/30 [==============================] - 18s 604ms/step - loss: 2.2410 - val_loss: 2.3035\n","Epoch 4/40\n","30/30 [==============================] - 18s 600ms/step - loss: 2.2652 - val_loss: 2.2948\n","Epoch 5/40\n","30/30 [==============================] - 18s 613ms/step - loss: 2.2667 - val_loss: 2.2936\n","Epoch 6/40\n","30/30 [==============================] - 18s 604ms/step - loss: 2.2286 - val_loss: 2.2865\n","Epoch 7/40\n","30/30 [==============================] - 19s 614ms/step - loss: 2.2176 - val_loss: 2.2844\n","Epoch 8/40\n","30/30 [==============================] - 19s 646ms/step - loss: 2.1990 - val_loss: 2.2759\n","Epoch 9/40\n","30/30 [==============================] - 19s 642ms/step - loss: 2.1585 - val_loss: 2.2676\n","Epoch 10/40\n","30/30 [==============================] - 19s 613ms/step - loss: 2.1800 - val_loss: 2.2662\n","Epoch 11/40\n","30/30 [==============================] - 19s 623ms/step - loss: 2.1641 - val_loss: 2.2511\n","Epoch 12/40\n","30/30 [==============================] - 18s 593ms/step - loss: 2.1575 - val_loss: 2.2443\n","Epoch 13/40\n","30/30 [==============================] - 18s 610ms/step - loss: 2.1359 - val_loss: 2.2309\n","Epoch 14/40\n","30/30 [==============================] - 19s 621ms/step - loss: 2.1419 - val_loss: 2.2233\n","Epoch 15/40\n","30/30 [==============================] - 19s 641ms/step - loss: 2.0892 - val_loss: 2.2122\n","Epoch 16/40\n","30/30 [==============================] - 19s 620ms/step - loss: 2.0937 - val_loss: 2.2032\n","Epoch 17/40\n","30/30 [==============================] - 18s 599ms/step - loss: 2.0490 - val_loss: 2.1923\n","Epoch 18/40\n","30/30 [==============================] - 18s 605ms/step - loss: 2.0309 - val_loss: 2.1872\n","Epoch 19/40\n","30/30 [==============================] - 17s 570ms/step - loss: 2.0627 - val_loss: 2.1663\n","Epoch 20/40\n","30/30 [==============================] - 19s 622ms/step - loss: 2.0213 - val_loss: 2.1574\n","Epoch 21/40\n","30/30 [==============================] - 18s 609ms/step - loss: 1.9767 - val_loss: 2.1363\n","Epoch 22/40\n","30/30 [==============================] - 19s 621ms/step - loss: 1.9837 - val_loss: 2.1331\n","Epoch 23/40\n","30/30 [==============================] - 18s 615ms/step - loss: 1.9571 - val_loss: 2.1250\n","Epoch 24/40\n","30/30 [==============================] - 18s 600ms/step - loss: 1.9192 - val_loss: 2.1128\n","Epoch 25/40\n","30/30 [==============================] - 18s 609ms/step - loss: 1.9362 - val_loss: 2.0964\n","Epoch 26/40\n","30/30 [==============================] - 18s 600ms/step - loss: 1.9096 - val_loss: 2.0890\n","Epoch 27/40\n","30/30 [==============================] - 19s 644ms/step - loss: 1.8793 - val_loss: 2.0828\n","Epoch 28/40\n","30/30 [==============================] - 19s 645ms/step - loss: 1.8678 - val_loss: 2.0756\n","Epoch 29/40\n","30/30 [==============================] - 17s 580ms/step - loss: 1.8607 - val_loss: 2.0500\n","Epoch 30/40\n","30/30 [==============================] - 19s 628ms/step - loss: 1.8091 - val_loss: 2.0577\n","Epoch 31/40\n","30/30 [==============================] - 18s 615ms/step - loss: 1.8241 - val_loss: 2.0397\n","Epoch 32/40\n","30/30 [==============================] - 18s 604ms/step - loss: 1.7920 - val_loss: 2.0279\n","Epoch 33/40\n","30/30 [==============================] - 18s 587ms/step - loss: 1.7775 - val_loss: 2.0236\n","Epoch 34/40\n","30/30 [==============================] - 19s 624ms/step - loss: 1.8180 - val_loss: 2.0162\n","Epoch 35/40\n","30/30 [==============================] - 17s 583ms/step - loss: 1.7467 - val_loss: 2.0167\n","Epoch 36/40\n","30/30 [==============================] - 18s 591ms/step - loss: 1.7191 - val_loss: 2.0003\n","Epoch 37/40\n","30/30 [==============================] - 18s 592ms/step - loss: 1.6816 - val_loss: 2.0054\n","Epoch 38/40\n","30/30 [==============================] - 18s 603ms/step - loss: 1.6623 - val_loss: 2.0040\n","Epoch 39/40\n","30/30 [==============================] - 19s 624ms/step - loss: 1.6839 - val_loss: 1.9776\n","Epoch 40/40\n","30/30 [==============================] - 17s 578ms/step - loss: 1.6715 - val_loss: 1.9687\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3e27530a10>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":666},"id":"anZUCjvt-pkf","executionInfo":{"status":"error","timestamp":1616517981642,"user_tz":-330,"elapsed":137805,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"3cbb01f8-1967-4a32-f581-e84c52161d6c"},"source":["model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","30/30 [==============================] - 18s 594ms/step - loss: 1.6409 - val_loss: 1.9708\n","Epoch 2/100\n","30/30 [==============================] - 19s 620ms/step - loss: 1.6241 - val_loss: 1.9662\n","Epoch 3/100\n","30/30 [==============================] - 18s 601ms/step - loss: 1.6067 - val_loss: 1.9604\n","Epoch 4/100\n","30/30 [==============================] - 18s 597ms/step - loss: 1.5891 - val_loss: 1.9544\n","Epoch 5/100\n","30/30 [==============================] - 17s 581ms/step - loss: 1.5730 - val_loss: 1.9537\n","Epoch 6/100\n","30/30 [==============================] - 18s 591ms/step - loss: 1.5600 - val_loss: 1.9370\n","Epoch 7/100\n","30/30 [==============================] - 19s 619ms/step - loss: 1.5440 - val_loss: 1.9534\n","Epoch 8/100\n","13/30 [============>.................] - ETA: 10s - loss: 1.5152"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-ece9faa0228e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZb9jX6o91uU","executionInfo":{"status":"ok","timestamp":1616501455699,"user_tz":-330,"elapsed":460111,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"d0a655ca-f9d7-4e3d-b252-0c0390f88419"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,100,38,39,100,'concat',100,64)\n","optimizer = tf.keras.optimizers.Adam()\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 18s 419ms/step - loss: 3.0607 - val_loss: 2.4684\n","Epoch 2/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.3780 - val_loss: 2.4156\n","Epoch 3/40\n","30/30 [==============================] - 11s 383ms/step - loss: 2.4028 - val_loss: 2.3981\n","Epoch 4/40\n","30/30 [==============================] - 11s 377ms/step - loss: 2.3232 - val_loss: 2.3855\n","Epoch 5/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.3508 - val_loss: 2.3808\n","Epoch 6/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2957 - val_loss: 2.3694\n","Epoch 7/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.2575 - val_loss: 2.3678\n","Epoch 8/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.3214 - val_loss: 2.3628\n","Epoch 9/40\n","30/30 [==============================] - 11s 375ms/step - loss: 2.2449 - val_loss: 2.3546\n","Epoch 10/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.2361 - val_loss: 2.3514\n","Epoch 11/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.2518 - val_loss: 2.3417\n","Epoch 12/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2155 - val_loss: 2.3342\n","Epoch 13/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2474 - val_loss: 2.3246\n","Epoch 14/40\n","30/30 [==============================] - 11s 375ms/step - loss: 2.2543 - val_loss: 2.3150\n","Epoch 15/40\n","30/30 [==============================] - 11s 370ms/step - loss: 2.2048 - val_loss: 2.3080\n","Epoch 16/40\n","30/30 [==============================] - 11s 364ms/step - loss: 2.1524 - val_loss: 2.2960\n","Epoch 17/40\n","30/30 [==============================] - 11s 379ms/step - loss: 2.1585 - val_loss: 2.2791\n","Epoch 18/40\n","30/30 [==============================] - 11s 380ms/step - loss: 2.0848 - val_loss: 2.2694\n","Epoch 19/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.1267 - val_loss: 2.2607\n","Epoch 20/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.0987 - val_loss: 2.2565\n","Epoch 21/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.0661 - val_loss: 2.2417\n","Epoch 22/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.0883 - val_loss: 2.2223\n","Epoch 23/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.0537 - val_loss: 2.2275\n","Epoch 24/40\n","30/30 [==============================] - 12s 397ms/step - loss: 1.9837 - val_loss: 2.2137\n","Epoch 25/40\n","30/30 [==============================] - 11s 383ms/step - loss: 1.9692 - val_loss: 2.2076\n","Epoch 26/40\n","30/30 [==============================] - 11s 373ms/step - loss: 1.9864 - val_loss: 2.1939\n","Epoch 27/40\n","30/30 [==============================] - 11s 373ms/step - loss: 1.9752 - val_loss: 2.1936\n","Epoch 28/40\n","30/30 [==============================] - 11s 371ms/step - loss: 1.9730 - val_loss: 2.1824\n","Epoch 29/40\n","30/30 [==============================] - 11s 375ms/step - loss: 1.9215 - val_loss: 2.1824\n","Epoch 30/40\n","30/30 [==============================] - 11s 382ms/step - loss: 1.8775 - val_loss: 2.1795\n","Epoch 31/40\n","30/30 [==============================] - 11s 382ms/step - loss: 1.8580 - val_loss: 2.1651\n","Epoch 32/40\n","30/30 [==============================] - 11s 383ms/step - loss: 1.8597 - val_loss: 2.1732\n","Epoch 33/40\n","30/30 [==============================] - 11s 381ms/step - loss: 1.8196 - val_loss: 2.1654\n","Epoch 34/40\n","30/30 [==============================] - 11s 377ms/step - loss: 1.8423 - val_loss: 2.1530\n","Epoch 35/40\n","30/30 [==============================] - 11s 381ms/step - loss: 1.7995 - val_loss: 2.1391\n","Epoch 36/40\n","30/30 [==============================] - 11s 381ms/step - loss: 1.8037 - val_loss: 2.1448\n","Epoch 37/40\n","30/30 [==============================] - 11s 375ms/step - loss: 1.7702 - val_loss: 2.1281\n","Epoch 38/40\n","30/30 [==============================] - 11s 376ms/step - loss: 1.7347 - val_loss: 2.1253\n","Epoch 39/40\n","30/30 [==============================] - 12s 384ms/step - loss: 1.6998 - val_loss: 2.1159\n","Epoch 40/40\n","30/30 [==============================] - 11s 378ms/step - loss: 1.7079 - val_loss: 2.1217\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1176428dd0>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Sstmr_UBKKn","executionInfo":{"status":"ok","timestamp":1616502323760,"user_tz":-330,"elapsed":457327,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"4fcdc826-ad2c-407a-d045-8775e507f7bb"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,100,38,39,100,'concat',100,64)\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 18s 418ms/step - loss: 3.1148 - val_loss: 3.2005\n","Epoch 2/40\n","30/30 [==============================] - 11s 374ms/step - loss: 3.1212 - val_loss: 3.1161\n","Epoch 3/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.9978 - val_loss: 2.9095\n","Epoch 4/40\n","30/30 [==============================] - 11s 376ms/step - loss: 2.8306 - val_loss: 2.7309\n","Epoch 5/40\n","30/30 [==============================] - 12s 385ms/step - loss: 2.6478 - val_loss: 2.6179\n","Epoch 6/40\n","30/30 [==============================] - 12s 384ms/step - loss: 2.5707 - val_loss: 2.5486\n","Epoch 7/40\n","30/30 [==============================] - 11s 370ms/step - loss: 2.4894 - val_loss: 2.5037\n","Epoch 8/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.4384 - val_loss: 2.4745\n","Epoch 9/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.4195 - val_loss: 2.4557\n","Epoch 10/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.3831 - val_loss: 2.4426\n","Epoch 11/40\n","30/30 [==============================] - 11s 375ms/step - loss: 2.4006 - val_loss: 2.4357\n","Epoch 12/40\n","30/30 [==============================] - 11s 376ms/step - loss: 2.3954 - val_loss: 2.4304\n","Epoch 13/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.3914 - val_loss: 2.4275\n","Epoch 14/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.4045 - val_loss: 2.4253\n","Epoch 15/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.3686 - val_loss: 2.4236\n","Epoch 16/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.3561 - val_loss: 2.4222\n","Epoch 17/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.3267 - val_loss: 2.4211\n","Epoch 18/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.3489 - val_loss: 2.4203\n","Epoch 19/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.3786 - val_loss: 2.4191\n","Epoch 20/40\n","30/30 [==============================] - 12s 384ms/step - loss: 2.3789 - val_loss: 2.4179\n","Epoch 21/40\n","30/30 [==============================] - 11s 377ms/step - loss: 2.3399 - val_loss: 2.4170\n","Epoch 22/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.3782 - val_loss: 2.4149\n","Epoch 23/40\n","30/30 [==============================] - 11s 377ms/step - loss: 2.3494 - val_loss: 2.4132\n","Epoch 24/40\n","30/30 [==============================] - 11s 368ms/step - loss: 2.3465 - val_loss: 2.4116\n","Epoch 25/40\n","30/30 [==============================] - 12s 393ms/step - loss: 2.3514 - val_loss: 2.4098\n","Epoch 26/40\n","30/30 [==============================] - 11s 379ms/step - loss: 2.2996 - val_loss: 2.4091\n","Epoch 27/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.3443 - val_loss: 2.4079\n","Epoch 28/40\n","30/30 [==============================] - 11s 367ms/step - loss: 2.3141 - val_loss: 2.4067\n","Epoch 29/40\n","30/30 [==============================] - 11s 366ms/step - loss: 2.3267 - val_loss: 2.4053\n","Epoch 30/40\n","30/30 [==============================] - 11s 367ms/step - loss: 2.3051 - val_loss: 2.4045\n","Epoch 31/40\n","30/30 [==============================] - 11s 370ms/step - loss: 2.3438 - val_loss: 2.4034\n","Epoch 32/40\n","30/30 [==============================] - 11s 379ms/step - loss: 2.3506 - val_loss: 2.4027\n","Epoch 33/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2964 - val_loss: 2.4015\n","Epoch 34/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.3522 - val_loss: 2.4014\n","Epoch 35/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.3130 - val_loss: 2.4001\n","Epoch 36/40\n","30/30 [==============================] - 11s 367ms/step - loss: 2.3569 - val_loss: 2.4000\n","Epoch 37/40\n","30/30 [==============================] - 11s 365ms/step - loss: 2.3325 - val_loss: 2.3987\n","Epoch 38/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.3061 - val_loss: 2.3984\n","Epoch 39/40\n","30/30 [==============================] - 11s 383ms/step - loss: 2.3054 - val_loss: 2.3971\n","Epoch 40/40\n","30/30 [==============================] - 11s 368ms/step - loss: 2.3062 - val_loss: 2.3966\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f10e878c0d0>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eIeUIBJC2cK","executionInfo":{"status":"ok","timestamp":1616503444270,"user_tz":-330,"elapsed":1110792,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"6df418c7-f2c6-45de-e450-dbd3184632d6"},"source":["model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.3231 - val_loss: 2.3952\n","Epoch 2/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.3215 - val_loss: 2.3937\n","Epoch 3/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.3199 - val_loss: 2.3931\n","Epoch 4/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.3178 - val_loss: 2.3921\n","Epoch 5/100\n","30/30 [==============================] - 11s 384ms/step - loss: 2.3162 - val_loss: 2.3907\n","Epoch 6/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.3145 - val_loss: 2.3901\n","Epoch 7/100\n","30/30 [==============================] - 11s 379ms/step - loss: 2.3127 - val_loss: 2.3891\n","Epoch 8/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.3111 - val_loss: 2.3884\n","Epoch 9/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.3093 - val_loss: 2.3875\n","Epoch 10/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.3076 - val_loss: 2.3868\n","Epoch 11/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.3060 - val_loss: 2.3862\n","Epoch 12/100\n","30/30 [==============================] - 11s 377ms/step - loss: 2.3045 - val_loss: 2.3851\n","Epoch 13/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.3027 - val_loss: 2.3849\n","Epoch 14/100\n","30/30 [==============================] - 11s 373ms/step - loss: 2.3012 - val_loss: 2.3834\n","Epoch 15/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2997 - val_loss: 2.3829\n","Epoch 16/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2979 - val_loss: 2.3825\n","Epoch 17/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2963 - val_loss: 2.3804\n","Epoch 18/100\n","30/30 [==============================] - 11s 374ms/step - loss: 2.2946 - val_loss: 2.3791\n","Epoch 19/100\n","30/30 [==============================] - 11s 372ms/step - loss: 2.2930 - val_loss: 2.3784\n","Epoch 20/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2913 - val_loss: 2.3774\n","Epoch 21/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.2896 - val_loss: 2.3764\n","Epoch 22/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.2879 - val_loss: 2.3753\n","Epoch 23/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2862 - val_loss: 2.3739\n","Epoch 24/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.2846 - val_loss: 2.3729\n","Epoch 25/100\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2829 - val_loss: 2.3717\n","Epoch 26/100\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2813 - val_loss: 2.3712\n","Epoch 27/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2793 - val_loss: 2.3691\n","Epoch 28/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2777 - val_loss: 2.3678\n","Epoch 29/100\n","30/30 [==============================] - 11s 372ms/step - loss: 2.2761 - val_loss: 2.3668\n","Epoch 30/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2745 - val_loss: 2.3657\n","Epoch 31/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2729 - val_loss: 2.3652\n","Epoch 32/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2713 - val_loss: 2.3641\n","Epoch 33/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.2694 - val_loss: 2.3622\n","Epoch 34/100\n","30/30 [==============================] - 11s 365ms/step - loss: 2.2675 - val_loss: 2.3615\n","Epoch 35/100\n","30/30 [==============================] - 11s 382ms/step - loss: 2.2655 - val_loss: 2.3604\n","Epoch 36/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2634 - val_loss: 2.3586\n","Epoch 37/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.2614 - val_loss: 2.3572\n","Epoch 38/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2596 - val_loss: 2.3570\n","Epoch 39/100\n","30/30 [==============================] - 12s 389ms/step - loss: 2.2576 - val_loss: 2.3557\n","Epoch 40/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2558 - val_loss: 2.3551\n","Epoch 41/100\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2538 - val_loss: 2.3538\n","Epoch 42/100\n","30/30 [==============================] - 11s 364ms/step - loss: 2.2520 - val_loss: 2.3530\n","Epoch 43/100\n","30/30 [==============================] - 11s 365ms/step - loss: 2.2498 - val_loss: 2.3516\n","Epoch 44/100\n","30/30 [==============================] - 11s 373ms/step - loss: 2.2478 - val_loss: 2.3504\n","Epoch 45/100\n","30/30 [==============================] - 11s 363ms/step - loss: 2.2453 - val_loss: 2.3489\n","Epoch 46/100\n","30/30 [==============================] - 11s 379ms/step - loss: 2.2424 - val_loss: 2.3475\n","Epoch 47/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2399 - val_loss: 2.3461\n","Epoch 48/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2375 - val_loss: 2.3443\n","Epoch 49/100\n","30/30 [==============================] - 11s 365ms/step - loss: 2.2350 - val_loss: 2.3437\n","Epoch 50/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2331 - val_loss: 2.3432\n","Epoch 51/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.2305 - val_loss: 2.3416\n","Epoch 52/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.2279 - val_loss: 2.3401\n","Epoch 53/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2256 - val_loss: 2.3400\n","Epoch 54/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2227 - val_loss: 2.3380\n","Epoch 55/100\n","30/30 [==============================] - 11s 365ms/step - loss: 2.2200 - val_loss: 2.3380\n","Epoch 56/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2173 - val_loss: 2.3367\n","Epoch 57/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2148 - val_loss: 2.3368\n","Epoch 58/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2123 - val_loss: 2.3353\n","Epoch 59/100\n","30/30 [==============================] - 11s 377ms/step - loss: 2.2097 - val_loss: 2.3327\n","Epoch 60/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.2071 - val_loss: 2.3325\n","Epoch 61/100\n","30/30 [==============================] - 11s 364ms/step - loss: 2.2046 - val_loss: 2.3325\n","Epoch 62/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.2017 - val_loss: 2.3313\n","Epoch 63/100\n","30/30 [==============================] - 11s 377ms/step - loss: 2.1991 - val_loss: 2.3304\n","Epoch 64/100\n","30/30 [==============================] - 11s 363ms/step - loss: 2.1963 - val_loss: 2.3299\n","Epoch 65/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1934 - val_loss: 2.3286\n","Epoch 66/100\n","30/30 [==============================] - 11s 375ms/step - loss: 2.1910 - val_loss: 2.3267\n","Epoch 67/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1885 - val_loss: 2.3250\n","Epoch 68/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.1860 - val_loss: 2.3245\n","Epoch 69/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.1836 - val_loss: 2.3233\n","Epoch 70/100\n","30/30 [==============================] - 11s 363ms/step - loss: 2.1811 - val_loss: 2.3229\n","Epoch 71/100\n","30/30 [==============================] - 11s 364ms/step - loss: 2.1785 - val_loss: 2.3220\n","Epoch 72/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.1759 - val_loss: 2.3222\n","Epoch 73/100\n","30/30 [==============================] - 11s 371ms/step - loss: 2.1733 - val_loss: 2.3217\n","Epoch 74/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.1709 - val_loss: 2.3208\n","Epoch 75/100\n","30/30 [==============================] - 11s 365ms/step - loss: 2.1685 - val_loss: 2.3174\n","Epoch 76/100\n","30/30 [==============================] - 11s 364ms/step - loss: 2.1666 - val_loss: 2.3175\n","Epoch 77/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1641 - val_loss: 2.3154\n","Epoch 78/100\n","30/30 [==============================] - 11s 367ms/step - loss: 2.1611 - val_loss: 2.3162\n","Epoch 79/100\n","30/30 [==============================] - 11s 378ms/step - loss: 2.1583 - val_loss: 2.3149\n","Epoch 80/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.1558 - val_loss: 2.3120\n","Epoch 81/100\n","30/30 [==============================] - 11s 363ms/step - loss: 2.1535 - val_loss: 2.3109\n","Epoch 82/100\n","30/30 [==============================] - 11s 362ms/step - loss: 2.1508 - val_loss: 2.3098\n","Epoch 83/100\n","30/30 [==============================] - 11s 364ms/step - loss: 2.1482 - val_loss: 2.3104\n","Epoch 84/100\n","30/30 [==============================] - 11s 365ms/step - loss: 2.1458 - val_loss: 2.3078\n","Epoch 85/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1434 - val_loss: 2.3076\n","Epoch 86/100\n","30/30 [==============================] - 11s 374ms/step - loss: 2.1407 - val_loss: 2.3082\n","Epoch 87/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.1384 - val_loss: 2.3049\n","Epoch 88/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1359 - val_loss: 2.3042\n","Epoch 89/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.1337 - val_loss: 2.3036\n","Epoch 90/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1313 - val_loss: 2.3016\n","Epoch 91/100\n","30/30 [==============================] - 11s 376ms/step - loss: 2.1293 - val_loss: 2.3060\n","Epoch 92/100\n","30/30 [==============================] - 11s 368ms/step - loss: 2.1270 - val_loss: 2.2983\n","Epoch 93/100\n","30/30 [==============================] - 11s 372ms/step - loss: 2.1249 - val_loss: 2.2988\n","Epoch 94/100\n","30/30 [==============================] - 11s 372ms/step - loss: 2.1220 - val_loss: 2.3002\n","Epoch 95/100\n","30/30 [==============================] - 11s 375ms/step - loss: 2.1194 - val_loss: 2.2965\n","Epoch 96/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.1169 - val_loss: 2.2960\n","Epoch 97/100\n","30/30 [==============================] - 11s 363ms/step - loss: 2.1147 - val_loss: 2.2984\n","Epoch 98/100\n","30/30 [==============================] - 11s 366ms/step - loss: 2.1121 - val_loss: 2.2958\n","Epoch 99/100\n","30/30 [==============================] - 11s 370ms/step - loss: 2.1097 - val_loss: 2.2945\n","Epoch 100/100\n","30/30 [==============================] - 11s 369ms/step - loss: 2.1077 - val_loss: 2.2947\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f10ac04a890>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Uk0M7x8tHYQj","executionInfo":{"status":"error","timestamp":1616503891273,"user_tz":-330,"elapsed":412194,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"c5771437-c887-4f00-8b65-960b49060fe8"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,100,38,39,100,'concat',100,64)\n","optimizer = tf.keras.optimizers.Adam(0.1)\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 18s 412ms/step - loss: 3.9617 - val_loss: 3.4156\n","Epoch 2/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.8160 - val_loss: 2.5687\n","Epoch 3/40\n","30/30 [==============================] - 11s 378ms/step - loss: 2.4718 - val_loss: 2.4137\n","Epoch 4/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.2830 - val_loss: 2.3402\n","Epoch 5/40\n","30/30 [==============================] - 11s 372ms/step - loss: 2.2488 - val_loss: 2.2761\n","Epoch 6/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.1767 - val_loss: 2.2434\n","Epoch 7/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.0705 - val_loss: 2.2030\n","Epoch 8/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.0143 - val_loss: 2.1875\n","Epoch 9/40\n","30/30 [==============================] - 11s 375ms/step - loss: 1.9741 - val_loss: 2.1875\n","Epoch 10/40\n","30/30 [==============================] - 11s 374ms/step - loss: 1.8782 - val_loss: 2.1599\n","Epoch 11/40\n","30/30 [==============================] - 11s 376ms/step - loss: 1.8605 - val_loss: 2.1737\n","Epoch 12/40\n","30/30 [==============================] - 11s 371ms/step - loss: 1.8496 - val_loss: 2.1823\n","Epoch 13/40\n","30/30 [==============================] - 11s 372ms/step - loss: 1.8184 - val_loss: 2.1897\n","Epoch 14/40\n","30/30 [==============================] - 11s 371ms/step - loss: 1.8574 - val_loss: 2.1989\n","Epoch 15/40\n","30/30 [==============================] - 11s 379ms/step - loss: 1.7756 - val_loss: 2.1853\n","Epoch 16/40\n","30/30 [==============================] - 11s 374ms/step - loss: 1.7580 - val_loss: 2.1822\n","Epoch 17/40\n","30/30 [==============================] - 11s 370ms/step - loss: 1.7403 - val_loss: 2.2478\n","Epoch 18/40\n","30/30 [==============================] - 11s 373ms/step - loss: 1.7995 - val_loss: 2.2413\n","Epoch 19/40\n","30/30 [==============================] - 11s 367ms/step - loss: 1.7117 - val_loss: 2.2573\n","Epoch 20/40\n","30/30 [==============================] - 11s 373ms/step - loss: 1.7186 - val_loss: 2.2746\n","Epoch 21/40\n","30/30 [==============================] - 11s 373ms/step - loss: 1.8112 - val_loss: 2.2690\n","Epoch 22/40\n","30/30 [==============================] - 11s 370ms/step - loss: 2.0014 - val_loss: 2.4176\n","Epoch 23/40\n","30/30 [==============================] - 11s 373ms/step - loss: 1.9616 - val_loss: 2.4053\n","Epoch 24/40\n","30/30 [==============================] - 11s 377ms/step - loss: 2.0722 - val_loss: 2.5050\n","Epoch 25/40\n","30/30 [==============================] - 11s 367ms/step - loss: 2.1114 - val_loss: 2.5626\n","Epoch 26/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.2499 - val_loss: 2.5034\n","Epoch 27/40\n","30/30 [==============================] - 11s 374ms/step - loss: 2.1722 - val_loss: 2.4693\n","Epoch 28/40\n","30/30 [==============================] - 11s 369ms/step - loss: 2.0875 - val_loss: 2.4425\n","Epoch 29/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.0457 - val_loss: 2.4449\n","Epoch 30/40\n","30/30 [==============================] - 11s 370ms/step - loss: 2.0501 - val_loss: 2.4034\n","Epoch 31/40\n","30/30 [==============================] - 11s 371ms/step - loss: 1.9978 - val_loss: 2.4746\n","Epoch 32/40\n","30/30 [==============================] - 11s 371ms/step - loss: 2.1453 - val_loss: 2.4796\n","Epoch 33/40\n","30/30 [==============================] - 11s 368ms/step - loss: 2.0862 - val_loss: 2.5243\n","Epoch 34/40\n","30/30 [==============================] - 11s 375ms/step - loss: 2.2578 - val_loss: 2.8153\n","Epoch 35/40\n","30/30 [==============================] - 11s 383ms/step - loss: 2.4445 - val_loss: 3.0515\n","Epoch 36/40\n","30/30 [==============================] - 11s 373ms/step - loss: 2.7724 - val_loss: 3.0258\n","Epoch 37/40\n"," 1/30 [>.............................] - ETA: 10s - loss: 2.8964"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-bc3c2ef8dfd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":972},"id":"pBGiJ1oO-06n","executionInfo":{"status":"error","timestamp":1616518334592,"user_tz":-330,"elapsed":306265,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"02fd8c69-79a9-41cc-84ca-34bd99fff816"},"source":["tf.keras.backend.clear_session()\n","train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 38,39)\n","test_dataset  = Dataset(test_data, tokenizer, tokenizer_e, 38,39)\n","train_dataloader = Dataloder(train_dataset, batch_size=64)\n","test_dataloader = Dataloder(test_dataset, batch_size=20)\n","model2=encoder_decoder(300,100,38,39,100,'concat',100,64)\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","model2.compile(optimizer=optimizer,loss=custom_lossfunction)\n","train_steps=train_data.shape[0]//64\n","valid_steps=test_data.shape[0]//20\n","model2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/40\n","30/30 [==============================] - 29s 684ms/step - loss: 2.6496 - val_loss: 2.3106\n","Epoch 2/40\n","30/30 [==============================] - 18s 598ms/step - loss: 2.2993 - val_loss: 2.2977\n","Epoch 3/40\n","30/30 [==============================] - 20s 665ms/step - loss: 2.2164 - val_loss: 2.2751\n","Epoch 4/40\n","30/30 [==============================] - 18s 608ms/step - loss: 2.1375 - val_loss: 2.2674\n","Epoch 5/40\n","30/30 [==============================] - 18s 610ms/step - loss: 2.1264 - val_loss: 2.2608\n","Epoch 6/40\n","30/30 [==============================] - 19s 622ms/step - loss: 2.0774 - val_loss: 2.2206\n","Epoch 7/40\n","30/30 [==============================] - 18s 605ms/step - loss: 2.0220 - val_loss: 2.1793\n","Epoch 8/40\n","30/30 [==============================] - 19s 646ms/step - loss: 1.9573 - val_loss: 2.1448\n","Epoch 9/40\n","30/30 [==============================] - 19s 638ms/step - loss: 1.9120 - val_loss: 2.1012\n","Epoch 10/40\n","30/30 [==============================] - 19s 615ms/step - loss: 1.8100 - val_loss: 2.0761\n","Epoch 11/40\n","30/30 [==============================] - 19s 647ms/step - loss: 1.7387 - val_loss: 2.0297\n","Epoch 12/40\n","30/30 [==============================] - 18s 595ms/step - loss: 1.6247 - val_loss: 1.9952\n","Epoch 13/40\n","30/30 [==============================] - 19s 625ms/step - loss: 1.5395 - val_loss: 1.9653\n","Epoch 14/40\n","30/30 [==============================] - 18s 596ms/step - loss: 1.4288 - val_loss: 1.9424\n","Epoch 15/40\n","30/30 [==============================] - 18s 584ms/step - loss: 1.3500 - val_loss: 1.9305\n","Epoch 16/40\n","24/30 [=======================>......] - ETA: 3s - loss: 1.3171"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-e5c06cd91482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5aYrgh8pF-T","executionInfo":{"status":"ok","timestamp":1616428538220,"user_tz":-330,"elapsed":1131,"user":{"displayName":"NIDHI AGRAWAL","photoUrl":"","userId":"09931979865334263524"}},"outputId":"4513f64d-0d0f-41ac-fc6e-25cc225de64e"},"source":["def predict(input_sentence):\n","\n","  '''\n","  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n","  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n","  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n","  D. till we reach max_length of decoder or till the model predicted word <end>:\n","         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n","         Save the attention weights\n","         And get the word using the tokenizer(word index) and then store it in a string.\n","  E. Call plot_attention(#params)\n","  F. Return the predicted sentence\n","\n","  '''\n","\n","\n","  input_sequence=tokenizer.texts_to_sequences([input_sentence])\n","  \n","\n","  inputs=pad_sequences(input_sequence,maxlen=38,padding='post')\n","  inputs=tf.convert_to_tensor(inputs)\n","  result=''\n","  units=256\n","  hidden=[tf.zeros((1,units))]\n","  encoder_output,hidden_state,cell_state=model2.layers[0](inputs,hidden)\n","  dec_hidden=hidden_state\n","  dec_input=tf.expand_dims([tokenizer_e.word_index['<start>']],0)\n","  for t in range(39):\n","      predictions,dec_hidden,cell_state,attention_weights,context_vector=model2.layers[1].onestepdecoder(dec_input,encoder_output,dec_hidden,cell_state)\n","\n","      predicted_id=tf.argmax(predictions[0]).numpy()\n","      result+=tokenizer_e.index_word[predicted_id]\n","      if tokenizer_e.word_index['<end>']==predicted_id:\n","          return result\n","      dec_input= tf.expand_dims([predicted_id],0)\n","  return result"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.encoder_decoder at 0x7f6d7ed914d0>"]},"metadata":{"tags":[]},"execution_count":25}]}]}